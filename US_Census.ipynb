{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "US Census",
      "provenance": [],
      "collapsed_sections": [
        "Cvq-SgnmYkbN",
        "P5L7rDOPTUr8",
        "TlKpvydETNAZ",
        "5ZorJZDVYp-r"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNlbXZBMrVzIVJVez/Ip5CG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/btrentini/data_science/blob/master/US_Census.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81CfsK3CSLmL"
      },
      "source": [
        "#US Census \n",
        "\n",
        "⚠ **Run notebook:** In the menu above click \"Runtime > Run all\" or press $CTRL + F9$   \n",
        "\n",
        "⚠ Heads up: this takes ~15 minutes on a Google Colab notebook with High RAM instance and a NVIDIA P100 GPU "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t885lixZdVUS"
      },
      "source": [
        "## Task Summary\n",
        "\n",
        "In summary, this noteboo intends to:\n",
        "\n",
        "- **Extract and Prepare** the dataset from http://thomasdata.s3.amazonaws.com/ds/us_census_full.zip\n",
        "- Provide **relevant EDA and Feature Engineering**\n",
        "- **Learn**, for a dataset formed by vectors $\\{x_n\\}_{n=0}^N$, N the number of training examples, a model for the label $y_n$.  \n",
        "- **Predict**, given an a vector $x_n=\\{x_n^0, x_n^1, ..., x_n^K\\}$, $K$ the number of features, if target variable, $y$ (income classification), is greater than or equal to \\$50,000 per year, yielding a prediction $\\hat{y_n}$ for each training example $x_n$.\n",
        "- **Test different models** and measure performance on test. We want to minimise the cross-entropy loss for the pairs $(y, \\hat{y})$ and measure Accuracy, Precision, Recall and F1-Scores. \n",
        "- **Highlight pain points** along the process\n",
        "- **Raise further ideas** about how to improve model performance and redress caveats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oNlPo0Xdc9w"
      },
      "source": [
        "## Task Info\n",
        "\n",
        "The following link lets you download an archive containing an “exercise” US Census dataset: http://thomasdata.s3.amazonaws.com/ds/us_census_full.zip\n",
        "This US Census dataset contains detailed but anonymized information for approximately 300,000 people.\n",
        "\n",
        ">The archive contains 3 files: \n",
        "* A large training file (csv)\n",
        "* Another test file (csv)\n",
        "* A metadata file (txt) describing the columns of the two csv files (identical for both)\n",
        "\n",
        "> **The goal** of this exercise is to model the information contained in the last column (42nd), i.e., whether a person makes more or less than $50,000 per year, from the information contained in the other columns. The exercise here consists of modeling a binary variable.\n",
        "\n",
        "> Work with Python (or R) to carry out the following steps:\n",
        "*  Load the train and test files.\n",
        "* Perform an exploratory analysis on the data and create some relevant visualisations.\n",
        "* Clean, preprocess, and engineer features in the training data, with the aim of building a data set that a model will perform well on.\n",
        "* Create a model using these features to predict whether a person earns more or less than $50,000 per year. Here, the idea is for you to test a few different models, and see whether there are any techniques you can apply to improve performance over your first results.\n",
        "* Choose the model that appears to have the highest performance based on a comparison between reality (the 42nd variable) and the model’s prediction. \n",
        "* Apply your model to the test file and measure its real performance on it (same method as above).\n",
        "\n",
        ">The goal of this exercise is not to create the best or the purest model, but rather to describe the steps you took to accomplish it.\n",
        "Explain areas that may have been the most challenging for you.\n",
        ">Find clear insights on the profiles of the people that make more than $50,000 / year. For example, which variables seem to be the most correlated with this phenomenon?\n",
        ">Finally, you push your code on GitHub to share it with me, or send it via email.\n",
        "\n",
        ">Once again, the goal of this exercise is not to solve this problem, but rather to spend a few hours on it and to thoroughly explain your approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mD8YwKdgTW"
      },
      "source": [
        "## Metadata Info\n",
        "\n",
        "**From the metadata (see below how this was obtained):**\n",
        "\n",
        "\n",
        "This data was extracted from the census bureau database found at http://www.census.gov/ftp/pub/DES/www/welcome.html\n",
        "\n",
        ">Donor: Terran Lane and Ronny Kohavi\n",
        "       Data Mining and Visualization\n",
        "       Silicon Graphics.\n",
        "       e-mail: terran@ecn.purdue.edu, ronnyk@sgi.com for questions.\n",
        "\n",
        "**Prediction task** is to determine the income level for the person represented by the record.  Incomes have been binned at the $50K level to present a binary classification problem, much like the original UCI/ADULT database.  The goal field of this data, however, was drawn from the \"total person income\" field rather than the \"adjusted gross income\" and may, therefore, behave differently than the orginal ADULT goal field.\n",
        "More information detailing the meaning of the attributes can be found in http://www.bls.census.gov/cps/cpsmain.htm\n",
        "\n",
        "The data was split into train/test in approximately $2/3$, $1/3$ proportions using MineSet's MIndUtil mineset-to-mlc.\n",
        "\n",
        "**Note**: We will use the 1/3 above as Test Set and will create another split of 1/3 from the train set as our cross-validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OBKRcB2nsAy"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWzMU7dj5UIT"
      },
      "source": [
        "## Check GPU configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7LH86If5PJo",
        "outputId": "9ab1ed50-db9d-4332-f883-4bf1e6cfc609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Sep 27 23:20:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    23W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzfveUw-5RfS",
        "outputId": "3e103e48-49a5-4bd5-c58a-3a31706b24d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVW8D1DcT8n3",
        "outputId": "47dc66eb-f4b3-4527-9757-233186b5d547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=9659906edf50b12c2c9b87c323a23c29671e91e00fe21eecf3b9959b584b5583\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awHcxkUbcf5F",
        "outputId": "e50f672b-91f4-46e0-9c86-de78cf56838d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install imbalanced-learn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNLO0gVNVcUH",
        "outputId": "db688812-e74a-4786-ece0-efe1a7f8d727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!pip install --upgrade seaborn"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl (283kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 235kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 245kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 276kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Installing collected packages: seaborn\n",
            "  Found existing installation: seaborn 0.10.1\n",
            "    Uninstalling seaborn-0.10.1:\n",
            "      Successfully uninstalled seaborn-0.10.1\n",
            "Successfully installed seaborn-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fuuDAjt5b8Q"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftiNwnIapM8Q"
      },
      "source": [
        "import time\n",
        "start_time = time.time()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ln5s1-7OVfj",
        "outputId": "e4bd7180-699b-4a29-c832-ede551b2c1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# System utils\n",
        "import sys\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Parallelism\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Some classic data science stuff\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "%matplotlib inline \n",
        "\n",
        "# Math & Stats\n",
        "import math \n",
        "import scipy.stats as stats\n",
        "from statsmodels.tools.tools import add_constant\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor  \n",
        "\n",
        "# Machine Learning libs\n",
        "from sklearn import svm\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier, plot_importance, plot_tree\n",
        "\n",
        "# Scikit learn utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.mixture import GaussianMixture\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNbDzwPuTelT"
      },
      "source": [
        "# Styling\n",
        "sns.set_style(\"ticks\", {\"xtick.major.size\": 11, \"ytick.major.size\": 11})\n",
        "sns.set_palette(\"inferno\")\n",
        "sns.set(font_scale = 2)\n",
        "figsize=(23, 15)\n",
        "pal='inferno'\n",
        "div = \"=\"*72"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hq-GXmVSwF7"
      },
      "source": [
        "# Build datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPQJnPZGeQ8e"
      },
      "source": [
        "## Download & Extract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX-F4BJ7S6XX",
        "outputId": "9d5c24d9-a9c6-4bd2-b778-da4a3394e625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget \"http://thomasdata.s3.amazonaws.com/ds/us_census_full.zip\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-27 23:21:02--  http://thomasdata.s3.amazonaws.com/ds/us_census_full.zip\n",
            "Resolving thomasdata.s3.amazonaws.com (thomasdata.s3.amazonaws.com)... 52.216.138.179\n",
            "Connecting to thomasdata.s3.amazonaws.com (thomasdata.s3.amazonaws.com)|52.216.138.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9801875 (9.3M) [application/zip]\n",
            "Saving to: ‘us_census_full.zip’\n",
            "\n",
            "us_census_full.zip  100%[===================>]   9.35M  12.0MB/s    in 0.8s    \n",
            "\n",
            "2020-09-27 23:21:03 (12.0 MB/s) - ‘us_census_full.zip’ saved [9801875/9801875]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV2CYp6XdZoX",
        "outputId": "73594755-5069-4ddf-be52-987ab02bce0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls -1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "us_census_full.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsmLt9msRGhL"
      },
      "source": [
        "# Define helper to load\n",
        "local_zip =os.path.join('/content', 'us_census_full.zip')\n",
        "\n",
        "# Unzip Train Set into temporary path\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZbPCGafRVYh",
        "outputId": "2e9b6f2c-6f69-4633-f849-fb3b6e6b1458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls -1 /tmp"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__MACOSX\n",
            "us_census_full\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h1tILn2RlvU"
      },
      "source": [
        "train     = '/tmp/us_census_full/census_income_learn.csv'\n",
        "test      = '/tmp/us_census_full/census_income_test.csv'\n",
        "metadata  = '/tmp/us_census_full/census_income_metadata.txt'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGnz5R76DvZf"
      },
      "source": [
        "## Metadata Investigation\n",
        "\n",
        "Let's see what's inside...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHoJp1ItR9gw",
        "outputId": "b412b416-2c16-4eaa-dd9f-6aad8da858bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's see what's in the metadata\n",
        "!fold -w 130 -s $metadata"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| This data was extracted from the census bureau database found at\n",
            "| http://www.census.gov/ftp/pub/DES/www/welcome.html\n",
            "| Donor: Terran Lane and Ronny Kohavi\n",
            "|        Data Mining and Visualization\n",
            "|        Silicon Graphics.\n",
            "|        e-mail: terran@ecn.purdue.edu, ronnyk@sgi.com for questions.\n",
            "|\n",
            "| The data was split into train/test in approximately 2/3, 1/3\n",
            "| proportions using MineSet's MIndUtil mineset-to-mlc.\n",
            "|\n",
            "| Prediction task is to determine the income level for the person\n",
            "| represented by the record.  Incomes have been binned at the $50K\n",
            "| level to present a binary classification problem, much like the\n",
            "| original UCI/ADULT database.  The goal field of this data, however,\n",
            "| was drawn from the \"total person income\" field rather than the\n",
            "| \"adjusted gross income\" and may, therefore, behave differently than the\n",
            "| orginal ADULT goal field.\n",
            "|\n",
            "| More information detailing the meaning of the attributes can be\n",
            "| found in http://www.bls.census.gov/cps/cpsmain.htm\n",
            "| To make use of the data descriptions at this site, the following mappings\n",
            "| to the Census Bureau's internal database column names will be needed:\n",
            "|\n",
            "| age\t\t\t\t\t\tAAGE\n",
            "| class of worker\t\t\t\tACLSWKR\n",
            "| industry code\t\t\t\t\tADTIND\n",
            "| occupation code\t\t\t\tADTOCC\n",
            "| adjusted gross income\t\t\t\tAGI\n",
            "| education\t\t\t\t\tAHGA\n",
            "| wage per hour\t\t\t\t\tAHRSPAY\n",
            "| enrolled in edu inst last wk\t\t\tAHSCOL\n",
            "| marital status\t\t\t\tAMARITL\n",
            "| major industry code\t\t\t\tAMJIND\n",
            "| major occupation code\t\t\t\tAMJOCC\n",
            "| mace\t\t\t\t\t\tARACE\n",
            "| hispanic Origin\t\t\t\tAREORGN\n",
            "| sex\t\t\t\t\t\tASEX\n",
            "| member of a labor union\t\t\tAUNMEM\n",
            "| reason for unemployment\t\t\tAUNTYPE\n",
            "| full or part time employment stat\t\tAWKSTAT\n",
            "| capital gains\t\t\t\t\tCAPGAIN\n",
            "| capital losses\t\t\t\tCAPLOSS\n",
            "| divdends from stocks\t\t\t\tDIVVAL\n",
            "| federal income tax liability\t\t\tFEDTAX\n",
            "| tax filer status\t\t\t\tFILESTAT\n",
            "| region of previous residence\t\t\tGRINREG\n",
            "| state of previous residence\t\t\tGRINST\n",
            "| detailed household and family stat\t\tHHDFMX\n",
            "| detailed household summary in household\tHHDREL\n",
            "| instance weight\t\t\t\tMARSUPWT\n",
            "| migration code-change in msa\t\t\tMIGMTR1\n",
            "| migration code-change in reg\t\t\tMIGMTR3\n",
            "| migration code-move within reg\t\tMIGMTR4\n",
            "| live in this house 1 year ago\t\t\tMIGSAME\n",
            "| migration prev res in sunbelt\t\t\tMIGSUN\n",
            "| num persons worked for employer\t\tNOEMP\n",
            "| family members under 18\t\t\tPARENT\n",
            "| total person earnings\t\t\t\tPEARNVAL\n",
            "| country of birth father\t\t\tPEFNTVTY\n",
            "| country of birth mother\t\t\tPEMNTVTY\n",
            "| country of birth self\t\t\t\tPENATVTY\n",
            "| citizenship\t\t\t\t\tPRCITSHP\n",
            "| total person income\t\t\t\tPTOTVAL\n",
            "| own business or self employed\t\t\tSEOTR\n",
            "| taxable income amount\t\t\t\tTAXINC\n",
            "| fill inc questionnaire for veteran's admin\tVETQVA\n",
            "| veterans benefits\t\t\t\tVETYN\n",
            "| weeks worked in year\t\t\t\tWKSWORK\n",
            "| \n",
            "| Basic statistics for this data set:\n",
            "|\n",
            "| Number of instances data = 199523\n",
            "|    Duplicate or conflicting instances : 46716\n",
            "| Number of instances in test = 99762\n",
            "|    Duplicate or conflicting instances : 20936\n",
            "| Class probabilities for income-projected.test file\n",
            "| Probability for the label '- 50000' : 93.80%\n",
            "| Probability for the label '50000+' : 6.20%\n",
            "| Majority accuracy: 93.80% on value - 50000\n",
            "| Number of attributes = 40 (continuous : 7 nominal : 33)\n",
            "| Information about .data file : \n",
            "|   91 distinct values for attribute #0 (age) continuous\n",
            "|    9 distinct values for attribute #1 (class of worker) nominal\n",
            "|   52 distinct values for attribute #2 (detailed industry recode) nominal\n",
            "|   47 distinct values for attribute #3 (detailed occupation recode) nominal\n",
            "|   17 distinct values for attribute #4 (education) nominal\n",
            "| 1240 distinct values for attribute #5 (wage per hour) continuous\n",
            "|    3 distinct values for attribute #6 (enroll in edu inst last wk) nominal\n",
            "|    7 distinct values for attribute #7 (marital stat) nominal\n",
            "|   24 distinct values for attribute #8 (major industry code) nominal\n",
            "|   15 distinct values for attribute #9 (major occupation code) nominal\n",
            "|    5 distinct values for attribute #10 (race) nominal\n",
            "|   10 distinct values for attribute #11 (hispanic origin) nominal\n",
            "|    2 distinct values for attribute #12 (sex) nominal\n",
            "|    3 distinct values for attribute #13 (member of a labor union) nominal\n",
            "|    6 distinct values for attribute #14 (reason for unemployment) nominal\n",
            "|    8 distinct values for attribute #15 (full or part time employment stat) nominal\n",
            "|  132 distinct values for attribute #16 (capital gains) continuous\n",
            "|  113 distinct values for attribute #17 (capital losses) continuous\n",
            "| 1478 distinct values for attribute #18 (dividends from stocks) continuous\n",
            "|    6 distinct values for attribute #19 (tax filer stat) nominal\n",
            "|    6 distinct values for attribute #20 (region of previous residence) nominal\n",
            "|   51 distinct values for attribute #21 (state of previous residence) nominal\n",
            "|   38 distinct values for attribute #22 (detailed household and family stat) nominal\n",
            "|    8 distinct values for attribute #23 (detailed household summary in household) nominal\n",
            "|   10 distinct values for attribute #24 (migration code-change in msa) nominal\n",
            "|    9 distinct values for attribute #25 (migration code-change in reg) nominal\n",
            "|   10 distinct values for attribute #26 (migration code-move within reg) nominal\n",
            "|    3 distinct values for attribute #27 (live in this house 1 year ago) nominal\n",
            "|    4 distinct values for attribute #28 (migration prev res in sunbelt) nominal\n",
            "|    7 distinct values for attribute #29 (num persons worked for employer) continuous\n",
            "|    5 distinct values for attribute #30 (family members under 18) nominal\n",
            "|   43 distinct values for attribute #31 (country of birth father) nominal\n",
            "|   43 distinct values for attribute #32 (country of birth mother) nominal\n",
            "|   43 distinct values for attribute #33 (country of birth self) nominal\n",
            "|    5 distinct values for attribute #34 (citizenship) nominal\n",
            "|    3 distinct values for attribute #35 (own business or self employed) nominal\n",
            "|    3 distinct values for attribute #36 (fill inc questionnaire for veteran's admin) nominal\n",
            "|    3 distinct values for attribute #37 (veterans benefits) nominal\n",
            "|   53 distinct values for attribute #38 (weeks worked in year) continuous\n",
            "|    2 distinct values for attribute #39 (year) nominal\n",
            "| \n",
            "|\n",
            "| Error rates:\n",
            "|    C4.5       \t: 4.8%\n",
            "|    C5.0\t\t: 4.7%\n",
            "|    C5.0 rules\t\t: 4.7%\n",
            "|    C5.0 boosting\t: 4.6%\n",
            "|    Naive-Bayes\t: 23.2%\n",
            "|\n",
            "| \n",
            "| All commas and periods were changed to spaces\n",
            "| Colons were replaced with dashes.\n",
            "|\n",
            "| The instance weight indicates the number of people in the population\n",
            "| that each record represents due to stratified sampling.\n",
            "| To do real analysis and derive conclusions, this field must be used.\n",
            "| This attribute should *not* be used in the classifiers, so it is\n",
            "| set to \"ignore\" in this file.\n",
            "|\n",
            "- 50000, 50000+.\n",
            "\n",
            "age: continuous.\n",
            "class of worker: Not in universe, Federal government, Local government, Never worked, Private, Self-employed-incorporated, \n",
            "Self-employed-not incorporated, State government, Without pay.\n",
            "detailed industry recode: 0, 40, 44, 2, 43, 47, 48, 1, 11, 19, 24, 25, 32, 33, 34, 35, 36, 37, 38, 39, 4, 42, 45, 5, 15, 16, 22, \n",
            "29, 31, 50, 14, 17, 18, 28, 3, 30, 41, 46, 51, 12, 13, 21, 23, 26, 6, 7, 9, 49, 27, 8, 10, 20.\n",
            "detailed occupation recode: 0, 12, 31, 44, 19, 32, 10, 23, 26, 28, 29, 42, 40, 34, 14, 36, 38, 2, 20, 25, 37, 41, 27, 24, 30, 43, \n",
            "33, 16, 45, 17, 35, 22, 18, 39, 3, 15, 13, 46, 8, 21, 9, 4, 6, 5, 1, 11, 7.\n",
            "education: Children, 7th and 8th grade, 9th grade, 10th grade, High school graduate, 11th grade, 12th grade no diploma, 5th or \n",
            "6th grade, Less than 1st grade, Bachelors degree(BA AB BS), 1st 2nd 3rd or 4th grade, Some college but no degree, Masters \n",
            "degree(MA MS MEng MEd MSW MBA), Associates degree-occup /vocational, Associates degree-academic program, Doctorate degree(PhD \n",
            "EdD), Prof school degree (MD DDS DVM LLB JD).\n",
            "wage per hour: continuous.\n",
            "enroll in edu inst last wk: Not in universe, High school, College or university.\n",
            "marital stat: Never married, Married-civilian spouse present, Married-spouse absent, Separated, Divorced, Widowed, Married-A F \n",
            "spouse present.\n",
            "major industry code: Not in universe or children, Entertainment, Social services, Agriculture, Education, Public administration, \n",
            "Manufacturing-durable goods, Manufacturing-nondurable goods, Wholesale trade, Retail trade, Finance insurance and real estate, \n",
            "Private household services, Business and repair services, Personal services except private HH, Construction, Medical except \n",
            "hospital, Other professional services, Transportation, Utilities and sanitary services, Mining, Communications, Hospital \n",
            "services, Forestry and fisheries, Armed Forces.\n",
            "major occupation code: Not in universe, Professional specialty, Other service, Farming forestry and fishing, Sales, Adm support \n",
            "including clerical, Protective services, Handlers equip cleaners etc , Precision production craft & repair, Technicians and \n",
            "related support, Machine operators assmblrs & inspctrs, Transportation and material moving, Executive admin and managerial, \n",
            "Private household services, Armed Forces.\n",
            "race: White, Black, Other, Amer Indian Aleut or Eskimo, Asian or Pacific Islander.\n",
            "hispanic origin: Mexican (Mexicano), Mexican-American, Puerto Rican, Central or South American, All other, Other Spanish, \n",
            "Chicano, Cuban, Do not know, NA.\n",
            "sex: Female, Male.\n",
            "member of a labor union: Not in universe, No, Yes.\n",
            "reason for unemployment: Not in universe, Re-entrant, Job loser - on layoff, New entrant, Job leaver, Other job loser.\n",
            "full or part time employment stat: Children or Armed Forces, Full-time schedules, Unemployed part- time, Not in labor force, \n",
            "Unemployed full-time, PT for non-econ reasons usually FT, PT for econ reasons usually PT, PT for econ reasons usually FT.\n",
            "capital gains: continuous.\n",
            "capital losses: continuous.\n",
            "dividends from stocks: continuous.\n",
            "tax filer stat: Nonfiler, Joint one under 65 & one 65+, Joint both under 65, Single, Head of household, Joint both 65+.\n",
            "region of previous residence: Not in universe, South, Northeast, West, Midwest, Abroad.\n",
            "state of previous residence: Not in universe, Utah, Michigan, North Carolina, North Dakota, Virginia, Vermont, Wyoming, West \n",
            "Virginia, Pennsylvania, Abroad, Oregon, California, Iowa, Florida, Arkansas, Texas, South Carolina, Arizona, Indiana, Tennessee, \n",
            "Maine, Alaska, Ohio, Montana, Nebraska, Mississippi, District of Columbia, Minnesota, Illinois, Kentucky, Delaware, Colorado, \n",
            "Maryland, Wisconsin, New Hampshire, Nevada, New York, Georgia, Oklahoma, New Mexico, South Dakota, Missouri, Kansas, Connecticut, \n",
            "Louisiana, Alabama, Massachusetts, Idaho, New Jersey.\n",
            "detailed household and family stat: Child <18 never marr not in subfamily, Other Rel <18 never marr child of subfamily RP, Other \n",
            "Rel <18 never marr not in subfamily, Grandchild <18 never marr child of subfamily RP, Grandchild <18 never marr not in subfamily, \n",
            "Secondary individual, In group quarters, Child under 18 of RP of unrel subfamily, RP of unrelated subfamily, Spouse of \n",
            "householder, Householder, Other Rel <18 never married RP of subfamily, Grandchild <18 never marr RP of subfamily, Child <18 never \n",
            "marr RP of subfamily, Child <18 ever marr not in subfamily, Other Rel <18 ever marr RP of subfamily, Child <18 ever marr RP of \n",
            "subfamily, Nonfamily householder, Child <18 spouse of subfamily RP, Other Rel <18 spouse of subfamily RP, Other Rel <18 ever marr \n",
            "not in subfamily, Grandchild <18 ever marr not in subfamily, Child 18+ never marr Not in a subfamily, Grandchild 18+ never marr \n",
            "not in subfamily, Child 18+ ever marr RP of subfamily, Other Rel 18+ never marr not in subfamily, Child 18+ never marr RP of \n",
            "subfamily, Other Rel 18+ ever marr RP of subfamily, Other Rel 18+ never marr RP of subfamily, Other Rel 18+ spouse of subfamily \n",
            "RP, Other Rel 18+ ever marr not in subfamily, Child 18+ ever marr Not in a subfamily, Grandchild 18+ ever marr not in subfamily, \n",
            "Child 18+ spouse of subfamily RP, Spouse of RP of unrelated subfamily, Grandchild 18+ ever marr RP of subfamily, Grandchild 18+ \n",
            "never marr RP of subfamily, Grandchild 18+ spouse of subfamily RP.\n",
            "detailed household summary in household: Child under 18 never married, Other relative of householder, Nonrelative of householder, \n",
            "Spouse of householder, Householder, Child under 18 ever married, Group Quarters- Secondary individual, Child 18 or older.\n",
            "| instance weight: ignore.\n",
            "instance weight: continuous.\n",
            "migration code-change in msa: Not in universe, Nonmover, MSA to MSA, NonMSA to nonMSA, MSA to nonMSA, NonMSA to MSA, Abroad to \n",
            "MSA, Not identifiable, Abroad to nonMSA.\n",
            "migration code-change in reg: Not in universe, Nonmover, Same county, Different county same state, Different state same division, \n",
            "Abroad, Different region, Different division same region.\n",
            "migration code-move within reg: Not in universe, Nonmover, Same county, Different county same state, Different state in West, \n",
            "Abroad, Different state in Midwest, Different state in South, Different state in Northeast.\n",
            "live in this house 1 year ago: Not in universe under 1 year old, Yes, No.\n",
            "migration prev res in sunbelt: Not in universe, Yes, No.\n",
            "num persons worked for employer: continuous.\n",
            "family members under 18: Both parents present, Neither parent present, Mother only present, Father only present, Not in universe.\n",
            "country of birth father: Mexico, United-States, Puerto-Rico, Dominican-Republic, Jamaica, Cuba, Portugal, Nicaragua, Peru, \n",
            "Ecuador, Guatemala, Philippines, Canada, Columbia, El-Salvador, Japan, England, Trinadad&Tobago, Honduras, Germany, Taiwan, \n",
            "Outlying-U S (Guam USVI etc), India, Vietnam, China, Hong Kong, Cambodia, France, Laos, Haiti, South Korea, Iran, Greece, Italy, \n",
            "Poland, Thailand, Yugoslavia, Holand-Netherlands, Ireland, Scotland, Hungary, Panama.\n",
            "country of birth mother: India, Mexico, United-States, Puerto-Rico, Dominican-Republic, England, Honduras, Peru, Guatemala, \n",
            "Columbia, El-Salvador, Philippines, France, Ecuador, Nicaragua, Cuba, Outlying-U S (Guam USVI etc), Jamaica, South Korea, China, \n",
            "Germany, Yugoslavia, Canada, Vietnam, Japan, Cambodia, Ireland, Laos, Haiti, Portugal, Taiwan, Holand-Netherlands, Greece, Italy, \n",
            "Poland, Thailand, Trinadad&Tobago, Hungary, Panama, Hong Kong, Scotland, Iran.\n",
            "country of birth self: United-States, Mexico, Puerto-Rico, Peru, Canada, South Korea, India, Japan, Haiti, El-Salvador, \n",
            "Dominican-Republic, Portugal, Columbia, England, Thailand, Cuba, Laos, Panama, China, Germany, Vietnam, Italy, Honduras, \n",
            "Outlying-U S (Guam USVI etc), Hungary, Philippines, Poland, Ecuador, Iran, Guatemala, Holand-Netherlands, Taiwan, Nicaragua, \n",
            "France, Jamaica, Scotland, Yugoslavia, Hong Kong, Trinadad&Tobago, Greece, Cambodia, Ireland.\n",
            "citizenship: Native- Born in the United States, Foreign born- Not a citizen of U S , Native- Born in Puerto Rico or U S Outlying, \n",
            "Native- Born abroad of American Parent(s), Foreign born- U S citizen by naturalization.\n",
            "own business or self employed: 0, 2, 1.\n",
            "fill inc questionnaire for veteran's admin: Not in universe, Yes, No.\n",
            "veterans benefits: 0, 2, 1.\n",
            "weeks worked in year: continuous.\n",
            "year: 94, 95.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vtj3S3yWUOj",
        "outputId": "54b99930-506d-4178-cca0-7e1d4f2a1c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Check if there's a header in the train file\n",
        "!head -2 $train"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73, Not in universe, 0, 0, High school graduate, 0, Not in universe, Widowed, Not in universe or children, Not in universe, White, All other, Female, Not in universe, Not in universe, Not in labor force, 0, 0, 0, Nonfiler, Not in universe, Not in universe, Other Rel 18+ ever marr not in subfamily, Other relative of householder, 1700.09, ?, ?, ?, Not in universe under 1 year old, ?, 0, Not in universe, United-States, United-States, United-States, Native- Born in the United States, 0, Not in universe, 2, 0, 95, - 50000.\n",
            "58, Self-employed-not incorporated, 4, 34, Some college but no degree, 0, Not in universe, Divorced, Construction, Precision production craft & repair, White, All other, Male, Not in universe, Not in universe, Children or Armed Forces, 0, 0, 0, Head of household, South, Arkansas, Householder, Householder, 1053.55, MSA to MSA, Same county, Same county, No, Yes, 1, Not in universe, United-States, United-States, United-States, Native- Born in the United States, 0, Not in universe, 2, 52, 94, - 50000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGctKhCXWl0w",
        "outputId": "95b8dc64-b4ac-494e-d6fb-327648737b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Check if there's a header in the test file\n",
        "!head -2 $test"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38, Private, 6, 36, 1st 2nd 3rd or 4th grade, 0, Not in universe, Married-civilian spouse present, Manufacturing-durable goods, Machine operators assmblrs & inspctrs, White, Mexican (Mexicano), Female, Not in universe, Not in universe, Full-time schedules, 0, 0, 0, Joint one under 65 & one 65+, Not in universe, Not in universe, Spouse of householder, Spouse of householder, 1032.38, ?, ?, ?, Not in universe under 1 year old, ?, 4, Not in universe, Mexico, Mexico, Mexico, Foreign born- Not a citizen of U S , 0, Not in universe, 2, 12, 95, - 50000.\n",
            "44, Self-employed-not incorporated, 37, 12, Associates degree-occup /vocational, 0, Not in universe, Married-civilian spouse present, Business and repair services, Professional specialty, White, All other, Female, Not in universe, Not in universe, PT for econ reasons usually PT, 0, 0, 2500, Joint both under 65, Not in universe, Not in universe, Spouse of householder, Spouse of householder, 1462.33, ?, ?, ?, Not in universe under 1 year old, ?, 1, Not in universe, United-States, United-States, United-States, Native- Born in the United States, 0, Not in universe, 2, 26, 95, - 50000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAYWLzTfR-WP",
        "outputId": "c9eda60f-e2e2-4ecb-e748-dc7540f8362d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Build DataFrames\n",
        "%time df  = pd.read_csv(train, header=None)\n",
        "%time t_df = pd.read_csv(test, header=None) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.21 s, sys: 107 ms, total: 1.31 s\n",
            "Wall time: 1.31 s\n",
            "CPU times: user 621 ms, sys: 18.5 ms, total: 639 ms\n",
            "Wall time: 638 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qoFDP9VVpVf",
        "outputId": "13b8870b-1ca6-423a-9b02-3f9a8e52e1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        }
      },
      "source": [
        "# Check\n",
        "df.head(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>73</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>High school graduate</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in labor force</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Other Rel 18+ ever marr not in subfamily</td>\n",
              "      <td>Other relative of householder</td>\n",
              "      <td>1700.09</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Not in universe under 1 year old</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Self-employed-not incorporated</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>Some college but no degree</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Construction</td>\n",
              "      <td>Precision production craft &amp; repair</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Children or Armed Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Head of household</td>\n",
              "      <td>South</td>\n",
              "      <td>Arkansas</td>\n",
              "      <td>Householder</td>\n",
              "      <td>Householder</td>\n",
              "      <td>1053.55</td>\n",
              "      <td>MSA to MSA</td>\n",
              "      <td>Same county</td>\n",
              "      <td>Same county</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>94</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10th grade</td>\n",
              "      <td>0</td>\n",
              "      <td>High school</td>\n",
              "      <td>Never married</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Asian or Pacific Islander</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in labor force</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Child 18+ never marr Not in a subfamily</td>\n",
              "      <td>Child 18 or older</td>\n",
              "      <td>991.95</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Not in universe under 1 year old</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Foreign born- Not a citizen of U S</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Children</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Never married</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Children or Armed Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Child &lt;18 never marr not in subfamily</td>\n",
              "      <td>Child under 18 never married</td>\n",
              "      <td>1758.14</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>Both parents present</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Children</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Never married</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Children or Armed Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Child &lt;18 never marr not in subfamily</td>\n",
              "      <td>Child under 18 never married</td>\n",
              "      <td>1069.16</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>Both parents present</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0                                1   2   3   ... 38  39  40         41\n",
              "0  73                  Not in universe   0   0  ...  2   0  95   - 50000.\n",
              "1  58   Self-employed-not incorporated   4  34  ...  2  52  94   - 50000.\n",
              "2  18                  Not in universe   0   0  ...  2   0  95   - 50000.\n",
              "3   9                  Not in universe   0   0  ...  0   0  94   - 50000.\n",
              "4  10                  Not in universe   0   0  ...  0   0  94   - 50000.\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TZZbcsDXId7"
      },
      "source": [
        "## A trick from metadata for column names\n",
        " This will help us a lot during EDA. The metada contains useful information about columns, values and their properties. I can use this file to name columns and later on this will give us the option to address the dataframe by column names, which might be handy in many cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJB6tkeYYnHZ",
        "outputId": "7813d086-7da1-4fd2-a17c-fc2c24c97d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "!tail -42 $metadata"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age: continuous.\n",
            "class of worker: Not in universe, Federal government, Local government, Never worked, Private, Self-employed-incorporated, Self-employed-not incorporated, State government, Without pay.\n",
            "detailed industry recode: 0, 40, 44, 2, 43, 47, 48, 1, 11, 19, 24, 25, 32, 33, 34, 35, 36, 37, 38, 39, 4, 42, 45, 5, 15, 16, 22, 29, 31, 50, 14, 17, 18, 28, 3, 30, 41, 46, 51, 12, 13, 21, 23, 26, 6, 7, 9, 49, 27, 8, 10, 20.\n",
            "detailed occupation recode: 0, 12, 31, 44, 19, 32, 10, 23, 26, 28, 29, 42, 40, 34, 14, 36, 38, 2, 20, 25, 37, 41, 27, 24, 30, 43, 33, 16, 45, 17, 35, 22, 18, 39, 3, 15, 13, 46, 8, 21, 9, 4, 6, 5, 1, 11, 7.\n",
            "education: Children, 7th and 8th grade, 9th grade, 10th grade, High school graduate, 11th grade, 12th grade no diploma, 5th or 6th grade, Less than 1st grade, Bachelors degree(BA AB BS), 1st 2nd 3rd or 4th grade, Some college but no degree, Masters degree(MA MS MEng MEd MSW MBA), Associates degree-occup /vocational, Associates degree-academic program, Doctorate degree(PhD EdD), Prof school degree (MD DDS DVM LLB JD).\n",
            "wage per hour: continuous.\n",
            "enroll in edu inst last wk: Not in universe, High school, College or university.\n",
            "marital stat: Never married, Married-civilian spouse present, Married-spouse absent, Separated, Divorced, Widowed, Married-A F spouse present.\n",
            "major industry code: Not in universe or children, Entertainment, Social services, Agriculture, Education, Public administration, Manufacturing-durable goods, Manufacturing-nondurable goods, Wholesale trade, Retail trade, Finance insurance and real estate, Private household services, Business and repair services, Personal services except private HH, Construction, Medical except hospital, Other professional services, Transportation, Utilities and sanitary services, Mining, Communications, Hospital services, Forestry and fisheries, Armed Forces.\n",
            "major occupation code: Not in universe, Professional specialty, Other service, Farming forestry and fishing, Sales, Adm support including clerical, Protective services, Handlers equip cleaners etc , Precision production craft & repair, Technicians and related support, Machine operators assmblrs & inspctrs, Transportation and material moving, Executive admin and managerial, Private household services, Armed Forces.\n",
            "race: White, Black, Other, Amer Indian Aleut or Eskimo, Asian or Pacific Islander.\n",
            "hispanic origin: Mexican (Mexicano), Mexican-American, Puerto Rican, Central or South American, All other, Other Spanish, Chicano, Cuban, Do not know, NA.\n",
            "sex: Female, Male.\n",
            "member of a labor union: Not in universe, No, Yes.\n",
            "reason for unemployment: Not in universe, Re-entrant, Job loser - on layoff, New entrant, Job leaver, Other job loser.\n",
            "full or part time employment stat: Children or Armed Forces, Full-time schedules, Unemployed part- time, Not in labor force, Unemployed full-time, PT for non-econ reasons usually FT, PT for econ reasons usually PT, PT for econ reasons usually FT.\n",
            "capital gains: continuous.\n",
            "capital losses: continuous.\n",
            "dividends from stocks: continuous.\n",
            "tax filer stat: Nonfiler, Joint one under 65 & one 65+, Joint both under 65, Single, Head of household, Joint both 65+.\n",
            "region of previous residence: Not in universe, South, Northeast, West, Midwest, Abroad.\n",
            "state of previous residence: Not in universe, Utah, Michigan, North Carolina, North Dakota, Virginia, Vermont, Wyoming, West Virginia, Pennsylvania, Abroad, Oregon, California, Iowa, Florida, Arkansas, Texas, South Carolina, Arizona, Indiana, Tennessee, Maine, Alaska, Ohio, Montana, Nebraska, Mississippi, District of Columbia, Minnesota, Illinois, Kentucky, Delaware, Colorado, Maryland, Wisconsin, New Hampshire, Nevada, New York, Georgia, Oklahoma, New Mexico, South Dakota, Missouri, Kansas, Connecticut, Louisiana, Alabama, Massachusetts, Idaho, New Jersey.\n",
            "detailed household and family stat: Child <18 never marr not in subfamily, Other Rel <18 never marr child of subfamily RP, Other Rel <18 never marr not in subfamily, Grandchild <18 never marr child of subfamily RP, Grandchild <18 never marr not in subfamily, Secondary individual, In group quarters, Child under 18 of RP of unrel subfamily, RP of unrelated subfamily, Spouse of householder, Householder, Other Rel <18 never married RP of subfamily, Grandchild <18 never marr RP of subfamily, Child <18 never marr RP of subfamily, Child <18 ever marr not in subfamily, Other Rel <18 ever marr RP of subfamily, Child <18 ever marr RP of subfamily, Nonfamily householder, Child <18 spouse of subfamily RP, Other Rel <18 spouse of subfamily RP, Other Rel <18 ever marr not in subfamily, Grandchild <18 ever marr not in subfamily, Child 18+ never marr Not in a subfamily, Grandchild 18+ never marr not in subfamily, Child 18+ ever marr RP of subfamily, Other Rel 18+ never marr not in subfamily, Child 18+ never marr RP of subfamily, Other Rel 18+ ever marr RP of subfamily, Other Rel 18+ never marr RP of subfamily, Other Rel 18+ spouse of subfamily RP, Other Rel 18+ ever marr not in subfamily, Child 18+ ever marr Not in a subfamily, Grandchild 18+ ever marr not in subfamily, Child 18+ spouse of subfamily RP, Spouse of RP of unrelated subfamily, Grandchild 18+ ever marr RP of subfamily, Grandchild 18+ never marr RP of subfamily, Grandchild 18+ spouse of subfamily RP.\n",
            "detailed household summary in household: Child under 18 never married, Other relative of householder, Nonrelative of householder, Spouse of householder, Householder, Child under 18 ever married, Group Quarters- Secondary individual, Child 18 or older.\n",
            "| instance weight: ignore.\n",
            "instance weight: continuous.\n",
            "migration code-change in msa: Not in universe, Nonmover, MSA to MSA, NonMSA to nonMSA, MSA to nonMSA, NonMSA to MSA, Abroad to MSA, Not identifiable, Abroad to nonMSA.\n",
            "migration code-change in reg: Not in universe, Nonmover, Same county, Different county same state, Different state same division, Abroad, Different region, Different division same region.\n",
            "migration code-move within reg: Not in universe, Nonmover, Same county, Different county same state, Different state in West, Abroad, Different state in Midwest, Different state in South, Different state in Northeast.\n",
            "live in this house 1 year ago: Not in universe under 1 year old, Yes, No.\n",
            "migration prev res in sunbelt: Not in universe, Yes, No.\n",
            "num persons worked for employer: continuous.\n",
            "family members under 18: Both parents present, Neither parent present, Mother only present, Father only present, Not in universe.\n",
            "country of birth father: Mexico, United-States, Puerto-Rico, Dominican-Republic, Jamaica, Cuba, Portugal, Nicaragua, Peru, Ecuador, Guatemala, Philippines, Canada, Columbia, El-Salvador, Japan, England, Trinadad&Tobago, Honduras, Germany, Taiwan, Outlying-U S (Guam USVI etc), India, Vietnam, China, Hong Kong, Cambodia, France, Laos, Haiti, South Korea, Iran, Greece, Italy, Poland, Thailand, Yugoslavia, Holand-Netherlands, Ireland, Scotland, Hungary, Panama.\n",
            "country of birth mother: India, Mexico, United-States, Puerto-Rico, Dominican-Republic, England, Honduras, Peru, Guatemala, Columbia, El-Salvador, Philippines, France, Ecuador, Nicaragua, Cuba, Outlying-U S (Guam USVI etc), Jamaica, South Korea, China, Germany, Yugoslavia, Canada, Vietnam, Japan, Cambodia, Ireland, Laos, Haiti, Portugal, Taiwan, Holand-Netherlands, Greece, Italy, Poland, Thailand, Trinadad&Tobago, Hungary, Panama, Hong Kong, Scotland, Iran.\n",
            "country of birth self: United-States, Mexico, Puerto-Rico, Peru, Canada, South Korea, India, Japan, Haiti, El-Salvador, Dominican-Republic, Portugal, Columbia, England, Thailand, Cuba, Laos, Panama, China, Germany, Vietnam, Italy, Honduras, Outlying-U S (Guam USVI etc), Hungary, Philippines, Poland, Ecuador, Iran, Guatemala, Holand-Netherlands, Taiwan, Nicaragua, France, Jamaica, Scotland, Yugoslavia, Hong Kong, Trinadad&Tobago, Greece, Cambodia, Ireland.\n",
            "citizenship: Native- Born in the United States, Foreign born- Not a citizen of U S , Native- Born in Puerto Rico or U S Outlying, Native- Born abroad of American Parent(s), Foreign born- U S citizen by naturalization.\n",
            "own business or self employed: 0, 2, 1.\n",
            "fill inc questionnaire for veteran's admin: Not in universe, Yes, No.\n",
            "veterans benefits: 0, 2, 1.\n",
            "weeks worked in year: continuous.\n",
            "year: 94, 95.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf1Dy9yRr3Ai"
      },
      "source": [
        "From the above we can see that the last 42 rows are the column names\n",
        "We can use this info to improve our datasets and help us eith EDA. Besides, the metada tells us to ignore '|_instance_weight' the 24th record\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJRGzAf8bol9"
      },
      "source": [
        "> 🤕 **Pain Point:** dataset cleaning is an art... platforms like [Dataiku](https://www.dataiku.com/) makes it much easier to repeat and visualise this process. Writing code for this, especially with many datasets, is super time-consuming (but has to be done!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzCgdwxDXQOl",
        "outputId": "c28f5f3d-c7f0-4599-e32d-e3849e0ec624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "# We will beed a list to append to...\n",
        "cols = []\n",
        "\n",
        "# Save metadata last 42 rows\n",
        "column_names = !tail -42 $metadata\n",
        "\n",
        "# Remove the record to be ignored '|_instance_weight'\n",
        "column_names.pop(24)        \n",
        "\n",
        "# Build column helper\n",
        "for col in column_names:\n",
        "  record = col.split(\":\")[0].replace(\" \",\"_\")\n",
        "  cols.append(record)\n",
        "\n",
        "# Add target variable's column not listed in metadata\n",
        "cols.append(\"target\")\n",
        "\n",
        "# Insert column names into dataframes\n",
        "df.columns = cols\n",
        "t_df.columns = cols\n",
        "\n",
        "# Voila!\n",
        "df.head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>class_of_worker</th>\n",
              "      <th>detailed_industry_recode</th>\n",
              "      <th>detailed_occupation_recode</th>\n",
              "      <th>education</th>\n",
              "      <th>wage_per_hour</th>\n",
              "      <th>enroll_in_edu_inst_last_wk</th>\n",
              "      <th>marital_stat</th>\n",
              "      <th>major_industry_code</th>\n",
              "      <th>major_occupation_code</th>\n",
              "      <th>race</th>\n",
              "      <th>hispanic_origin</th>\n",
              "      <th>sex</th>\n",
              "      <th>member_of_a_labor_union</th>\n",
              "      <th>reason_for_unemployment</th>\n",
              "      <th>full_or_part_time_employment_stat</th>\n",
              "      <th>capital_gains</th>\n",
              "      <th>capital_losses</th>\n",
              "      <th>dividends_from_stocks</th>\n",
              "      <th>tax_filer_stat</th>\n",
              "      <th>region_of_previous_residence</th>\n",
              "      <th>state_of_previous_residence</th>\n",
              "      <th>detailed_household_and_family_stat</th>\n",
              "      <th>detailed_household_summary_in_household</th>\n",
              "      <th>instance_weight</th>\n",
              "      <th>migration_code-change_in_msa</th>\n",
              "      <th>migration_code-change_in_reg</th>\n",
              "      <th>migration_code-move_within_reg</th>\n",
              "      <th>live_in_this_house_1_year_ago</th>\n",
              "      <th>migration_prev_res_in_sunbelt</th>\n",
              "      <th>num_persons_worked_for_employer</th>\n",
              "      <th>family_members_under_18</th>\n",
              "      <th>country_of_birth_father</th>\n",
              "      <th>country_of_birth_mother</th>\n",
              "      <th>country_of_birth_self</th>\n",
              "      <th>citizenship</th>\n",
              "      <th>own_business_or_self_employed</th>\n",
              "      <th>fill_inc_questionnaire_for_veteran's_admin</th>\n",
              "      <th>veterans_benefits</th>\n",
              "      <th>weeks_worked_in_year</th>\n",
              "      <th>year</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>73</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>High school graduate</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in labor force</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Other Rel 18+ ever marr not in subfamily</td>\n",
              "      <td>Other relative of householder</td>\n",
              "      <td>1700.09</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Not in universe under 1 year old</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>Self-employed-not incorporated</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>Some college but no degree</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Construction</td>\n",
              "      <td>Precision production craft &amp; repair</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Male</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Children or Armed Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Head of household</td>\n",
              "      <td>South</td>\n",
              "      <td>Arkansas</td>\n",
              "      <td>Householder</td>\n",
              "      <td>Householder</td>\n",
              "      <td>1053.55</td>\n",
              "      <td>MSA to MSA</td>\n",
              "      <td>Same county</td>\n",
              "      <td>Same county</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>94</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10th grade</td>\n",
              "      <td>0</td>\n",
              "      <td>High school</td>\n",
              "      <td>Never married</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Asian or Pacific Islander</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in labor force</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Child 18+ never marr Not in a subfamily</td>\n",
              "      <td>Child 18 or older</td>\n",
              "      <td>991.95</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Not in universe under 1 year old</td>\n",
              "      <td>?</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>Foreign born- Not a citizen of U S</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Children</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Never married</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Children or Armed Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Child &lt;18 never marr not in subfamily</td>\n",
              "      <td>Child under 18 never married</td>\n",
              "      <td>1758.14</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>Both parents present</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Children</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Never married</td>\n",
              "      <td>Not in universe or children</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>White</td>\n",
              "      <td>All other</td>\n",
              "      <td>Female</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Children or Armed Forces</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nonfiler</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>Child &lt;18 never marr not in subfamily</td>\n",
              "      <td>Child under 18 never married</td>\n",
              "      <td>1069.16</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Nonmover</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>Both parents present</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>United-States</td>\n",
              "      <td>Native- Born in the United States</td>\n",
              "      <td>0</td>\n",
              "      <td>Not in universe</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>- 50000.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age                  class_of_worker  ...  year     target\n",
              "0   73                  Not in universe  ...    95   - 50000.\n",
              "1   58   Self-employed-not incorporated  ...    94   - 50000.\n",
              "2   18                  Not in universe  ...    95   - 50000.\n",
              "3    9                  Not in universe  ...    94   - 50000.\n",
              "4   10                  Not in universe  ...    94   - 50000.\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvzpPKvlhpEW",
        "outputId": "196feed4-34e6-48e3-b477-429456f70fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df.target.value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " - 50000.    187141\n",
              " 50000+.      12382\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwqM_P2ojb6W"
      },
      "source": [
        "**Note:** Dataset quite unbalanced...So we have two options:\n",
        "\n",
        "- Either do Downscaling / Upscaling; Or\n",
        "- Create a method that accounts for this imbalance in the proper way\n",
        "\n",
        "I often prefer the second as we need to model the data's true nature. Advanced techniques exist (deriving from Bayesian Methods, for example), but since I know some \"off-the-shelf\" models can help us in this classification problem, so I'll focus on them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYNFQUMbwghU"
      },
      "source": [
        "## Categorise data \n",
        "\n",
        "Lets convert objects into categorical values so that we can manipulate them numerically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3at83Tc69aX"
      },
      "source": [
        "# This ensures there wont be empty spaces in the strings to avoid\n",
        "#         creating categories that don't actually exist\n",
        "\n",
        "obj = df.select_dtypes(['object'])\n",
        "df[obj.columns] = obj.apply(lambda x: x.str.strip().replace(\" \",\"\"))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB7Bikf4ROu8"
      },
      "source": [
        "> 🤕 **Pain Point:** Sometimes we override parts or entire datasets by mistake and then we need to restart the process. Here I am saving checkpoints due to the \"continuous\" nature of Colab Notebooks, but @Dataiku's DSS platform would make it much easier with visual recipes to prepare the data... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_DGRLCJzaG8",
        "outputId": "947cb024-b5e6-48ca-e061-29e125f6d938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        }
      },
      "source": [
        "# Safety backup. In a low-memory / large dataset context I wouldn't do it\n",
        "df_bkp = df.copy()\n",
        "t_df = t_df.copy()\n",
        "\n",
        "for col in df.columns:\n",
        "  if df[col].dtype == 'object':\n",
        "    df[col] = df[col].str.strip().replace(\" \",\"\").astype('category').cat.codes\n",
        "    t_df[col] = t_df[col].str.strip().replace(\" \",\"\").astype('category').cat.codes\n",
        "\n",
        "df.dtypes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                                             int64\n",
              "class_of_worker                                  int8\n",
              "detailed_industry_recode                        int64\n",
              "detailed_occupation_recode                      int64\n",
              "education                                        int8\n",
              "wage_per_hour                                   int64\n",
              "enroll_in_edu_inst_last_wk                       int8\n",
              "marital_stat                                     int8\n",
              "major_industry_code                              int8\n",
              "major_occupation_code                            int8\n",
              "race                                             int8\n",
              "hispanic_origin                                  int8\n",
              "sex                                              int8\n",
              "member_of_a_labor_union                          int8\n",
              "reason_for_unemployment                          int8\n",
              "full_or_part_time_employment_stat                int8\n",
              "capital_gains                                   int64\n",
              "capital_losses                                  int64\n",
              "dividends_from_stocks                           int64\n",
              "tax_filer_stat                                   int8\n",
              "region_of_previous_residence                     int8\n",
              "state_of_previous_residence                      int8\n",
              "detailed_household_and_family_stat               int8\n",
              "detailed_household_summary_in_household          int8\n",
              "instance_weight                               float64\n",
              "migration_code-change_in_msa                     int8\n",
              "migration_code-change_in_reg                     int8\n",
              "migration_code-move_within_reg                   int8\n",
              "live_in_this_house_1_year_ago                    int8\n",
              "migration_prev_res_in_sunbelt                    int8\n",
              "num_persons_worked_for_employer                 int64\n",
              "family_members_under_18                          int8\n",
              "country_of_birth_father                          int8\n",
              "country_of_birth_mother                          int8\n",
              "country_of_birth_self                            int8\n",
              "citizenship                                      int8\n",
              "own_business_or_self_employed                   int64\n",
              "fill_inc_questionnaire_for_veteran's_admin       int8\n",
              "veterans_benefits                               int64\n",
              "weeks_worked_in_year                            int64\n",
              "year                                            int64\n",
              "target                                           int8\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCWb4udrsHMF"
      },
      "source": [
        "## Are there null / undefined values?\n",
        "\n",
        "There are a few records marked with \"$?$\" but we will treat these as a category... I understand \"unkown\" values also have their importance for some models. **Another option:** I could infer the values of \"?\" based on the dataset, but that's a different task and may require some time...\n",
        "\n",
        "I could also \"exclude\" all rows containing \"?\" but I may as well lose important information.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ej-RSZOiHhN",
        "outputId": "70853d84-f475-4f84-eeff-a88818091ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "null_columns=df.columns[df.isnull().any()]\n",
        "if len(null_columns) > 0:\n",
        "  print(df[null_columns].isnull().sum())\n",
        "else:\n",
        "  print(\"No null columns\")\n",
        "\n",
        "na_columns=df.columns[df.isna().any()]\n",
        "if len(na_columns) > 0:\n",
        "  print(df[na_columns].isna().sum())\n",
        "else:\n",
        "  print(\"No NA columns\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No null columns\n",
            "No NA columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN2HNhaoXR40"
      },
      "source": [
        "## Are there duplicates?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkoaD4elXXkJ",
        "outputId": "8520519a-24e2-4814-d94c-e1186706e34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if df.duplicated().sum() > 0:\n",
        "  print(df.duplicated().sum(), \" dupicated records found and dropped\")\n",
        "  df.drop_duplicates(inplace=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3229  dupicated records found and dropped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whontM4MfVEM"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hfy6mSffY5a"
      },
      "source": [
        "We not necessarily need to add more features to our dataset. In fact, for binary classification models in many cases we have more features than we need. We can go a lot deeper in the analyses to come up with good features. \n",
        "\n",
        "For example, *in 1995 the average workweek for men was 42.1h and 35.8h for woman* according to the report [Hours of Work Since the Mid-70's](https://www.bls.gov/opub/mlr/1997/04/art1full.pdf) compiled by Philip L. Rones, former Assistant Commissionerfor Current Employment Analysis, Bureau of Labor Statistics. The study also pointed that persons aged 25-54 worked more hours than older and younger people. Besides, workweek hours was also influenced by industry (Agricultural workers had a different schedule than most \"office\" workers) and marital status (married men tended to work more hours than married woman). There's also a distribution on work hours within each group (for examle, only 46% of people aged 25 to 54 years would work 40h a week). Therefore, we can go super deep into feature engineering, but we will make good (but rather loose) assumptions. **For example, the study points out the average workweek was 39.2h**. We don't have this feature and this alone don't bring a lot more insights than \"weeks_worked_in_year\". But it can be useful to calculate \"total_income\"\n",
        "\n",
        "> \"Sex\" is not balanced (we have circa 8% more females than males in our trianing set). For this reason we will use Pilip L. Rones individual averages to compute new features. \n",
        "\n",
        "Therefore, it would make sense to create a feature for total income $I = \\overline{h}_{sex} * w * H$. Where $I$ is the total income in a year, $\\overline{h}_{sex}$ is the average weekly hours by sex, $w$ is the total number of weeks worked in a year and $H$ the total number of hours worked per week. \n",
        "\n",
        "Let's see if that feature will contribute to our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg8--d-SfYUm",
        "outputId": "8790ed6f-1aa8-4842-fcc2-373a650655aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "fig, ax=plt.subplots(figsize=(8,5))\n",
        "sex_balance = 1-(df[df.sex == 1].sex.value_counts().values[0] / df[df.sex == 0].sex.value_counts().values[0])\n",
        "sns.barplot(x=df.sex.unique(), palette=pal, \n",
        "            y=df.sex.value_counts().values).\\\n",
        "            set_title('\\nfemale:male {}%\\n'.format(round(100*sex_balance,2)));\n",
        "\n",
        "plt.xticks(rotation=0, fontsize=21)\n",
        "ax.set_xticklabels(['Female', 'Male'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'Female'), Text(0, 0, 'Male')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY6grzbTgSJw",
        "outputId": "0fccb363-4236-4c26-dd47-bd3e785b3a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"We have wage AND weeks worked for {}% of the dataset\".format(\n",
        "    round(100*len(df[(df.wage_per_hour!=0) & (df.weeks_worked_in_year!=0)])/len(df),2)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have wage AND weeks worked for 5.61% of the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByO3F9QPgf0o"
      },
      "source": [
        "Since we have many '0's in the weeks_worked_in_year and wage_per_hour fields (~95% of the dataset), we get would get $I$ for only 3% of the records. \n",
        "\n",
        "That doesn't look very promising... *I honestly think this feature will harm the model since we have so limited data to calculate total annual income...but I won't pretend I didn't consider it :)*\n",
        "\n",
        "> 😫 **Pain point**: For now I won't create a lot of features as I don't know how an initial model performs and am not sure about the bias/variation trade-off in this case.... Usually feature engineering requires many lines of code. Dataiku would make it so easy with a recipe and documentation of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrmdLlOUag26"
      },
      "source": [
        "# Technical EDA \n",
        "\n",
        "In this section our objective is to find correlations and potential risks of collinearity. Demographics EDA is next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fIco2eMgCTy"
      },
      "source": [
        "## Feature Importance\n",
        "\n",
        "Let's begin with a simple light GBM for estimating feature importance. \n",
        "\n",
        "This model could be used for predictions, but just to have some variablity, I will use this for feature estimation and XGBoost for modelling / predictions. The same model could be used for both purposes... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlhxcRqehvxE"
      },
      "source": [
        "model = LGBMClassifier(learning_rate=0.01, num_leaves= 33, random_state=77)\n",
        "model.fit(df.iloc[:,:-1], df.iloc[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z6ARSQ9g2uc"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(figsize))\n",
        "ax = sns.barplot(y=model.feature_importances_, x=df.iloc[:,:-1].columns, palette=pal)\n",
        "plt.xticks(rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy9oRlcrsF6w"
      },
      "source": [
        "🚨 *INTERESTING!*\n",
        "\n",
        "**This is very strange!** in real life we know that age, although a good indicator, can't play alone such an important weight in determining someone's income. There must exist some colinearity in the data (or worse things!). Let's check:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp4-7mwuoDlk"
      },
      "source": [
        "## Correlation\n",
        "\n",
        "Tjhis will help us understand risks of colinearity and some features that we can scrap. We will only consider removing features with moderate (>0.5), strong (>0.7) and very strong (>0.9) correlation in absolute values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9sWWoJGgA5S"
      },
      "source": [
        "correlation = df.drop(['target'], axis=1).corr()\n",
        "mask = np.triu(correlation)\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(23,23))\n",
        "  #ax = sns.heatmap(correlation[(correlation > 0.5) | (correlation < -0.5)],\n",
        "  ax = sns.heatmap(correlation,\n",
        "              square=True,\n",
        "              vmax=1.0,\n",
        "              vmin=-1.0,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              mask=mask,\n",
        "              annot=False, \n",
        "              fmt=\".2f\",\n",
        "              robust=True,\n",
        "              cbar=True,\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvq-SgnmYkbN"
      },
      "source": [
        "### Variance Inflation Factor(VIF)\n",
        "From WikiPedia: VIF is the quotient of the variance in a model with multiple terms by the variance of a model with one term alone. It quantifies the severity of multicollinearity in an ordinary least squares regression analysis. It provides an index that measures how much the variance (the square of the estimate's standard deviation) of an estimated regression coefficient is increased because of collinearity.\n",
        "\n",
        "> Multicollinearity is a common phenomenon in high‐dimensional settings, in which two or more predictor variables are highly correlated [Zhao et al, 2020]( https://doi.org/10.1002/sta4.272)\n",
        "\n",
        "This is a bit of a controversial topic and \"tule of thumb\" tresholds are dangerous as pointed in [A Caution Regarding Rules of Thumb\n",
        "for Variance Inflation Factors](https://www.researchgate.net/profile/Robert_Obrien8/publication/226005307_A_Caution_Regarding_Rules_of_Thumb_for_Variance_Inflation_Factors/links/54d0f2620cf298d656695641/A-Caution-Regarding-Rules-of-Thumb-for-Variance-Inflation-Factors.pdf). The lowest VIF valuee is 1. Anything beyond 10 is extreme. Most people choose either $3$, $4$ or $5$ as treshold. We will go with $4$.\n",
        "\n",
        "❌ We have $k=41$ features. With large $k$ this would be innapropriate but there are solusions like the one proposed in [Zhao et al, 2020]( https://doi.org/10.1002/sta4.272)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0lMU06H6YFJ"
      },
      "source": [
        "X = add_constant(df.iloc[:,0:-1])\n",
        "multico_indx=pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOLDo3ix-xcu"
      },
      "source": [
        "sns.distplot(multico_indx, rug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhyaWPMJfTuZ"
      },
      "source": [
        "df.iloc[:,np.where((multico_indx[1:] < 4)==True)[0][:].tolist()].dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DDSZXe3GzWf"
      },
      "source": [
        "df = df.iloc[:,np.where((multico_indx[1:] < 4)==True)[0][:].tolist()]\n",
        "df['target'] = df_bkp['target'].astype('category').cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRmDcR1kHgkX"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIU2HOZSqUOp"
      },
      "source": [
        "### Post-VIF check feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsf0R6GuqYTc"
      },
      "source": [
        "model = LGBMClassifier(learning_rate=0.01, num_leaves= 33, random_state=77)\n",
        "model.fit(df.iloc[:,:-1], df.iloc[:,-1])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(figsize))\n",
        "ax = sns.barplot(y=model.feature_importances_, x=df.iloc[:,:-1].columns, palette=pal)\n",
        "plt.xticks(rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsETv3BrskvV"
      },
      "source": [
        "> **✅ That makes more sense!**\n",
        "We now see a greater importance of \"Capital Gains\" and \"Capital Losses\" and \"Dividends\". Indeed, if someone has the profile of an investor, it might be a good indicator that this person earns > 50K\n",
        "\n",
        "Likewise, **age, education, industry**.... are also factorrs we normally understand as a good indicator of someone's income (sometimes by common sense / experience). *Therefore, as we can see, our feature selection makes sense*. There are still some \"unimportant\" features, but for now we can leave them as they can help reduce the \"weights\" of our predictions and / or produce a more general model (we will see!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJ_sXsBbazN"
      },
      "source": [
        "### Post-VIF check correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgoWFDjZa5XQ"
      },
      "source": [
        "correlation = df.drop(['target'], axis=1).corr()\n",
        "mask = np.triu(correlation)\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(23,23))\n",
        "  #ax = sns.heatmap(correlation[(correlation > 0.5) | (correlation < -0.5)],\n",
        "  ax = sns.heatmap(correlation,\n",
        "              square=True,\n",
        "              vmax=1.0,\n",
        "              vmin=-1.0,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              mask=mask,\n",
        "              annot=False, \n",
        "              fmt=\".2f\",\n",
        "              robust=True,\n",
        "              cbar=True,\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8QFBsDKGQst"
      },
      "source": [
        "## Remove not-so-important features and / or with moderate correaltion or higher\n",
        "\n",
        "This is due to mathematical requirements. We want to avoid singularities and undetermined matrices in our algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjw4hlzgKvPB"
      },
      "source": [
        "It Looks like country of birth from father and mother are moderately correlated with citizenship. Since we can (almost) always derive someone's citizenship from their parents' place of birth and assuming parents' nationality do not play an imediate factor in someone's wages (setting apart deeper social analyses) and considering neither parent's origin appears as a crucial feature in our Light GBM model, we will remove these features to simplify our model further"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW915kP1Je6j"
      },
      "source": [
        "df.drop(columns=['country_of_birth_father'], inplace=True)\n",
        "df.drop(columns=['country_of_birth_mother'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXcuJKlhKJHK"
      },
      "source": [
        "There's a moderate linear relationship between the industry of a person with its ocupation and the number of persons worked for employer. Althought these shouldn't affect our model aggressively, we can infer one by the other (for instance: we assume that someone's occupation is highly related to its industry and that its industry can tell information about the number of people per employer. Think about Social Media industry versus Manufacuring plant.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCp9dxWcJ-ky"
      },
      "source": [
        "df.drop(columns=['detailed_occupation_recode'], inplace=True)\n",
        "df.drop(columns=['num_persons_worked_for_employer'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaO4q8ZtLBiT"
      },
      "source": [
        "We can see in [Hours of Work Since the Mid-70's](https://www.bls.gov/opub/mlr/1997/04/art1full.pdf) compiled by Philip L. Rones, former USA Assistant Commissioner for Current Employment Analysis, Bureau of Labor Statistics, that marital status can influence totall income (married people tend to work less hours in a week, according to his 1995 report). The EDA also reveleaded that \"Age\" is an important factor. So...\n",
        "\n",
        "**From the metadata**\n",
        "> tax filer stat: Nonfiler, Joint one under 65 & one 65+, Joint both under 65, Single, Head of household, Joint both 65+.\n",
        "\n",
        "We see a \"duplication\" between this and *marital_stat* and *age*...So This will not add extra info that we haven't already obtained... so we will get rid of that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QksnpSBoLBJF"
      },
      "source": [
        "df.drop(columns=['tax_filer_stat'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZEjRdZtVaFj"
      },
      "source": [
        "Let's visualise it again: no moderate correlations or worse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLtCrvMKJu0n"
      },
      "source": [
        "correlation = df.drop(['target'], axis=1).corr()\n",
        "mask = np.triu(correlation)\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(23,23))\n",
        "  ax = sns.heatmap(correlation[(correlation > 0.5) | (correlation < -0.5)],\n",
        "  #ax = sns.heatmap(correlation,\n",
        "              square=True,\n",
        "              vmax=1.0,\n",
        "              vmin=-1.0,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              mask=mask,\n",
        "              annot=False, \n",
        "              fmt=\".2f\",\n",
        "              robust=True,\n",
        "              cbar=True,\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTGf-T1TNnxY"
      },
      "source": [
        "**NICE!** *So no correlations greater than 0.5 or less than -0.5. Let's plot the rest:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJEQQMOaNyiI"
      },
      "source": [
        "correlation = df.drop(['target'], axis=1).corr()\n",
        "mask = np.triu(correlation)\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(23,23))\n",
        "  #ax = sns.heatmap(correlation[(correlation > 0.5) | (correlation < -0.5)],\n",
        "  ax = sns.heatmap(correlation,\n",
        "              square=True,\n",
        "              vmax=1.0,\n",
        "              vmin=-1.0,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              mask=mask,\n",
        "              annot=True,\n",
        "              fmt=\".1f\",\n",
        "              robust=True,\n",
        "              cbar=True,\n",
        "              annot_kws={\"size\": 16},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnPXQk5OwUF2"
      },
      "source": [
        "# Demographics EDA\n",
        "\n",
        "We now know the most important features, *according to the lightGBM model*. Let's try to get further insights from this by exploring our data a little further and then come up with a simple hypothesis to test and a prediction model.\n",
        "\n",
        "We will create a new dataset keeping the categories just for analysis!\n",
        "\n",
        "> 🤕 **Pain Point:** I wish I could have a 'recipe' for obtaining the cateories and keep the data analysis unafected without having to 'allocate more stuff' in memory... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r57JdQmObaN"
      },
      "source": [
        "# Lets use the non categorized dataset for some analyses\n",
        "eda = df_bkp.loc[:, df.columns.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VO_v-94wXN_"
      },
      "source": [
        "## Understanding Age better\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEup2KZ-a1vE"
      },
      "source": [
        "**Warm up:** Age was pointed as an important feature. Do we have a population that is equally distirbuted in terms of age? \n",
        "\n",
        "No. We can see that 50% of the population is 35 years old or younger. We have the next 30% at circa 60 years old or less. We can also confirm that by fitting a log-gama distribution over the data (second chart, black line).\n",
        "\n",
        "By the manifest we know this data comprises the years 1994 and 1995. Therefore, **we can do some fact checking**: we see that indeed between 1990 and 2000 the median age of the United States was around 35 years old (despite the fact the census data only includes the Economic Active Population)\n",
        "\n",
        "<a href=\"https://www.statista.com/statistics/241494/median-age-of-the-us-population/\" rel=\"nofollow\"><img src=\"https://www.statista.com/graphic/1/241494/median-age-of-the-us-population.jpg\" alt=\"Statistic: Median age of the resident population of the United States from 1960 to 2019 | Statista\" style=\"width: 100%; height: auto !important; max-width:1000px;-ms-interpolation-mode: bicubic;\"/></a><br />Find more statistics at  <a href=\"https://www.statista.com\" rel=\"nofollow\">Statista</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOob7R0RrIGm"
      },
      "source": [
        "# Bimodal data, 50% of population less than 35yo\n",
        "fig, ax = plt.subplots(2, 1, figsize=figsize)\n",
        "kwargs = {'cumulative': True}\n",
        "\n",
        "g1 = sns.distplot(eda['age'], hist_kws=kwargs, kde_kws=kwargs, ax=ax[0], axlabel=None,\n",
        "                  fit=stats.gamma, bins=10)\n",
        "g2 = sns.distplot(eda['age'], rug=True, ax=ax[1], fit=stats.loggamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY2TxWHHYH_m"
      },
      "source": [
        "How about the target by age? We can see that 50% of those earning $< 50$K are around 30~35 years old or younger. On the other hand, 50% of those earning $>50$K are older than 45 years ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3HHmKThUhFL"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(figsize))\n",
        "g = sns.boxplot(y='age', x='target', data=eda, palette=pal)\n",
        "plt.xticks(rotation=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMY6WpFxtWiU"
      },
      "source": [
        "As expected, **age** will play a role in our predictions. Common knowledge tells us that, in rare expections, someone who's starting their career will earn less than someone at more senior levels (usually a consequence of experience that comes with ageing). Likewise, retired people tend to earn less than those who are economically active.  This is a straight-forward assumption. **So let's try some more involved hypothesis without looking into the data.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PkPUPlVRejj"
      },
      "source": [
        "## Understand Capital Gains versus Age\n",
        "\n",
        "We will combine stocks performance (this will become a new feature later on!) to see if \"investors profile\" have higher wages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJv10n3uTqwK"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "cap = eda.capital_losses - eda.capital_losses + eda.dividends_from_stocks \n",
        "\n",
        "sns.scatterplot(x=\"age\", y=cap.values,\n",
        "                hue=\"target\", \n",
        "                palette=pal,\n",
        "                sizes=(1, 8), linewidth=0,\n",
        "                data=eda, ax=ax)\n",
        "\n",
        "plt.suptitle(\"Stock Performance  as a function of Age and their influence in total income\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65zEk2O_juBb"
      },
      "source": [
        "Judging by this plot: there are several people who make +50K as income, but whose stocks gain are below 20,000. This means that a \"investor\" profile may not necessarily make more than 30,000 in a \"usual\" job. Besides, we see some outliers: people making 100K+ in stocks alone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TibtzpMP5DV"
      },
      "source": [
        "## Other Social Indicators vs Income\n",
        "We will explore if social indicators such as  Sex, Race, Citizenship has any pattern in regards to the target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A65M7wa3-wp8"
      },
      "source": [
        "### Age groups and nationalities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqqw9A17P5In"
      },
      "source": [
        "g = sns.catplot(x=\"target\", y=\"age\",\n",
        "                hue=\"race\", col=\"sex\",\n",
        "                palette=pal, legend=False,\n",
        "                data=eda, kind=\"box\");\n",
        "g.fig.set_size_inches(23,13)\n",
        "plt.legend(bbox_to_anchor=(0.85,-.15), ncol=len(eda.race.unique().tolist()))\n",
        "plt.xticks(rotation=0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrQ0kpPEup8D"
      },
      "source": [
        "Interesting... It seems like although \"White\" and \"Black\" races are quite balanced in terms of spread of age (disconsidering outliers) for males, but not for females where \"Blacks\" are somehwat younger (3rd quantile closer to 40s than 60s).\n",
        "\n",
        "As for the other races, there's clearly a concentration of younger people regardless of their income group. What stands out is the presence of 'other' races where the majority of people making under 50K are around 20 years old for both makes and females. Let's go deeper into that.\n",
        "\n",
        "**Deep Dive into 'Other':**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7vYMuXy67cy"
      },
      "source": [
        "# We already check if there are NAs or nulls, so we can safely count with\n",
        "f, ax = plt.subplots(figsize=figsize)\n",
        "y = eda[eda.race=='Other'].groupby('citizenship').age.count().values\n",
        "x = eda.citizenship.unique()\n",
        "\n",
        "ax = sns.barplot(x=x, y=y, palette='cividis')\n",
        "plt.xticks(rotation=90, fontsize=23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SWastw2-ReH"
      },
      "source": [
        "Ok. We have a mix of backgrounds here, with the majority being from Puerto Rico or US Outlying. The total number of people in this category is immaterial, **so shouldn't influence our predictions too much**. **Just out of curiosity, let's check their demographics.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O267QZ5J6iLw"
      },
      "source": [
        "**⚠** **ATTENTION**: Plots have been inverted. Argument order=['A', 'B'] of catplot did not work this time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLjwxeFXP5M1"
      },
      "source": [
        "g = sns.catplot(x=\"race\", y=\"age\",\n",
        "                hue=\"citizenship\", col=\"sex\",\n",
        "                palette=pal, legend=False, legend_out=False,\n",
        "                data=eda[eda.race == 'Other'], kind=\"box\");\n",
        "\n",
        "plt.legend(loc='lower center', ncol=3, bbox_to_anchor=(0,-0.15))\n",
        "g.fig.set_size_inches(23,23)\n",
        "plt.xticks(rotation=0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQu8SBUG641W"
      },
      "source": [
        "### Education influence on income group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7pQoIUTP4jv"
      },
      "source": [
        "aux = pd.DataFrame(eda.groupby(['target', 'education']).\\\n",
        "                   age.count(), index=None).reset_index().\\\n",
        "                   rename(columns={'age': 'count'}).\\\n",
        "                   sort_values(by=['target','count'], ascending=False).reset_index()\n",
        "\n",
        "g = sns.catplot(x=\"education\", y=\"count\",\n",
        "                hue=\"target\", col=\"target\", sharey=False,\n",
        "                data=aux, kind=\"bar\", palette=pal)\n",
        "\n",
        "g.fig.set_size_inches(15, 8)\n",
        "g.set_xticklabels(fontsize=15, rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd9eCKPbMBmn"
      },
      "source": [
        "**It is clear that the data is skewed** with more people in the lower income group (probability of picking someone at random and get income group = -50K is 93%, according to the metadata).Nonetheless, we can see that people with less income are, in its majority, from lower educational backgrounds while the group earning +50K have, in its majority, at least a Bachelor's Degree. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcZKRpmINZTv"
      },
      "source": [
        "## Relation between (some of the) most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-T4QvXaNv_X"
      },
      "source": [
        "sns.relplot(\n",
        "    data=eda, height=18, aspect=0.5,\n",
        "    x=\"age\", y=\"education\", col='sex',\n",
        "    hue=\"target\", size=cap,\n",
        "    palette=pal, sizes=(10, 200),\n",
        ")\n",
        "g.set(xscale=\"log\", yscale=\"log\")\n",
        "g.despine(left=True)\n",
        "plt.yticks(fontsize=13)\n",
        "#plt.legend(loc='lower center', bbox_to_anchor=(0.35,-0.35), ncol = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeIGPX0ZPYUW"
      },
      "source": [
        "**Look how interesting:** there's a strong indication that higher education leads to more stock investments (juding by the circle sizes), which leads to higher annual income (juding by the color). The circles sizes represent how much investment there's in the stock market.\n",
        "\n",
        "One concern: children in the data? Child labour? Error in the data....? This might be beyond our goal for EDA for today!\n",
        "\n",
        "Another interesting point is the difference between Male x Female in \"High School Graduate\" education level. This 1995 data. Perhaps it has changed a lot since then? (We hope so!).\n",
        "\n",
        "At least from Master's level, sex disparity is not so aggressive. For PhDs we again see more men than women in the top-tier earning\n",
        "\n",
        "This presentation from the US Census Bureau shows important changes in demographics since 1995: https://www.census.gov/newsroom/pdf/women_workforce_slides.pdf \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61roeoXlXvF3"
      },
      "source": [
        "> The EDA above helps us further understand the relationships between the data point and the target variable and reveal deeper social issues to be investigated. **Indeed the EDA** above helps us have reasonable assurance that the lightGBM model has classified feature importance in a meaningful way. We can proceed to some hypothesis testing and the classification / prediction task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdGnZREWKQHO"
      },
      "source": [
        "## Release memory, things not needed go to trash\n",
        "del aux "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZeEjDHcrS1"
      },
      "source": [
        "# Hypothesis Test 1: Constructors vs Educators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8h8chOXcuEa"
      },
      "source": [
        "**Let's pretend we have some questions and distill the following hypothesis without looking into the data (only using statistics)**\n",
        "\n",
        "\"There's a better chance of seeing more *Construction* workers among the top earners in comparison to *Education* workers\"\n",
        "\n",
        ">$H_0: \\, \\, $ Equal chances of *Construction* workers and *Education* workers to earn +50K  ($\\theta=0.5$)    \n",
        ">$H_1: \\, \\, $ There's a higher chance of *Construction* workers to b earning earning  +50K versus *Education* workers ($\\theta > 0.5$)  \n",
        "\n",
        "\n",
        "Where $H_0$ is our null hypothesis and $H_1$ is our alternative hypothesis, our test will be conducted at a significance level of 5%\n",
        "\n",
        "\n",
        "🚀 Let's skip EDA for the industry and try to answer two hypothesis with the high level of confidence in a statistical way\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnNdR8JBfjRu"
      },
      "source": [
        "# Let's first compute the proportion of construction workers and educators among the top earners\n",
        "test_statistic = eda[(eda.major_industry_code==\"Construction\")].groupby(\"target\").count().T.reset_index().iloc[:,0:3].iloc[0][2]\n",
        "complement = eda[(eda.major_industry_code==\"Education\")].groupby(\"target\").count().T.reset_index().iloc[:,0:3].iloc[0][2]\n",
        "\n",
        "# How many observations do we have in total\n",
        "N = test_statistic+complement\n",
        "\n",
        "# And for each of our target observations\n",
        "print(\"Total Construction and Education Workers earning +50K = \", N, test_statistic+complement==N)\n",
        "print(\"--- construction =\", test_statistic)\n",
        "print(\"--- education =\", complement)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_vlg6-Fi8XT"
      },
      "source": [
        "**To simplify, we can model this as a binomial distribution** (seeing construction workers in the high earning group is considered success)\n",
        "\n",
        "*Level = 5%*:  Decreasing this will decrease our critical region (region where we fail\n",
        " o reject the null hypothesis if the p-value falls within)\n",
        "\n",
        "*p=0.5:*  We want to test if the propability of seeing constructors and educators are the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSlwiznwrjYo"
      },
      "source": [
        "level=0.05\n",
        "p=0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy8OKDaMjYAW"
      },
      "source": [
        "print(f\"Within the 50K+ target we have seen {N} constructors and educators\")\n",
        "print(f\"{test_statistic} of them are in the Construction Sector ({round(test_statistic/N,2)*100}%)\\n\")\n",
        "print(f\"\\nH0 : The proportion of consutrction workers as top earners is the same as educators (param = {p})\")\n",
        "print(f\"H1 : There are fewer construction workers earning 50K+ than educators (param < {p})\\n\")\n",
        "\n",
        "%time p_value = np.sum([stats.binom_test(x, N, p=0.5, alternative='greater') for x in range(test_statistic)])\n",
        "\n",
        "print(\"\\n\\t Sum p-values\", p_value)\n",
        "\n",
        "print(\"\\n\", div)\n",
        "if p_value < level:\n",
        "  print('''\\nTHEREFORE We reject the null hypothesis H0.\n",
        "  There is enough evidence at 5% level of significance to suggest that \n",
        "  Considering only educators and constructors,\n",
        "  the observation is not due to chance\n",
        "  \\n>> Constructors and Educators are not equally likely among the top earners\\n''')\n",
        "else:\n",
        "  print('''\\nTHEREFORE We FAIL to reject the null hypotehesis H0.\n",
        "  There is enough evidence at 5% level of significance to suggest that \n",
        "  Considering only educators and constructors,\n",
        "  the observation is not due to chance\n",
        "  \\n>> constructors and educators are balanced as top earners\\n''')\n",
        "print(div)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ9jUkGb3iyL"
      },
      "source": [
        "# Hypothesis 2: What if we compare Education against Entertainment workers? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0vBvSbF39yZ"
      },
      "source": [
        "**Let's distill the following hypothesis:**\n",
        "\n",
        "\"US is the land of Holywood and we know many people don't have access to good education. So Education workers are less prone to be among top earners (50K+) than Entertainment workers\". \n",
        "\n",
        ">$H_0: \\, \\, $ Equal chance of *Education* workers earning  +50K,as *Educators* workers   ($\\theta=0.5$)    \n",
        ">$H_1: \\, \\, $ There's a lower chance of seeing *Education* workers earning  +50K in comparison to *Entertainment* workers ($\\theta < 0.5$)  \n",
        "\n",
        "\n",
        "Once again, $H_0$ is our null hypothesis and $H_1$ is our alternative hypothesis, our test will be conducted at a significance level of 5%\n",
        "\n",
        "\n",
        "🚀 No EDA, yes Stats.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGB5DDIU5hSu"
      },
      "source": [
        "# Let's first compute the proportion of construction workers and educators among the top earners\n",
        "test_statistic = eda[(eda.major_industry_code==\"Education\")].groupby(\"target\").count().T.reset_index().iloc[:,0:3].iloc[0][2]\n",
        "complement =  eda[(eda.major_industry_code==\"Entertainment\")].groupby(\"target\").count().T.reset_index().iloc[:,0:3].iloc[0][2]\n",
        "\n",
        "# How many observations do we have in total\n",
        "N = test_statistic+complement\n",
        "print(\"Total Education and Entertainment workers earning +50K = \", N, test_statistic+complement==N)\n",
        "print(\"--- Education =\", test_statistic)\n",
        "print(\"--- Entertainment =\", complement)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0OpBkDt5mbt"
      },
      "source": [
        "level=0.05\n",
        "p=0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y97OkBA25oU8"
      },
      "source": [
        "print(f\"Within the 50K+ target we have seen {N} Educators and Entertainers\")\n",
        "print(f\"{test_statistic} of them are in the Educators Sector ({round(test_statistic/N,2)*100}%)\\n\")\n",
        "print(f\"\\nH0 : The proportion of Educators workers as top earners is the same as Entertainers (param = {p})\")\n",
        "print(f\"H1 : There are fewer Education workers earning 50K+ than Entertainers (param < {p})\\n\")\n",
        "\n",
        "%time p_value = np.sum([stats.binom_test(x, N, p=0.5, alternative='less') for x in range(test_statistic)])\n",
        "\n",
        "print(\"\\n\\tSum p-values\", p_value)\n",
        "\n",
        "print(\"\\n\", div)\n",
        "\n",
        "if p_value < level:\n",
        "  print('''\\nTHEREFORE We reject the null hypothesis H0.\n",
        "  There is enough evidence at 5% level of significance to suggest that,\n",
        "  Considering only Educators and Entertainers,\n",
        "  the observation is not due to chance\n",
        "  \\n>> there are more Educators than Entertainers in the top earners\\n''')\n",
        "else:\n",
        "  print('''\\nTHEREFORE We FAIL to reject the null hypotehesis H0.\n",
        "  There is enough evidence at 5% level of significance to suggest that \n",
        "  the observation is not due to chance\n",
        "  \\n>> Educators and Entertainers are balanced among top earners\\n''')\n",
        "print(div)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5L7rDOPTUr8"
      },
      "source": [
        "# Machine Learning\n",
        "\n",
        "🚨 **HEADS UP** We will first try some models on the Test and Validation Sets and assess performance of all models in the test set later on!\n",
        "\n",
        "> 🤕 **Pain Point**: some models can take a long time to run. If only I could easily track performance \"on-the-fly\"... Especially Deep Learning models, it's so frustrating when you tune hyperparameters and it doesn't converge...\n",
        "\n",
        "> 🤕 **Paint Point**: I wish there was a better way to document hyperparameter testing so I can retrieve the best model (Grid Search might do, but I wish I could have more control upon feature selection, hyperparams and checkpoints....)\n",
        "\n",
        "\n",
        "> Tip: Dataiku DSS could easily help me resolve these...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA-pfXBT1Ko4"
      },
      "source": [
        "## Split Train into Train (70%) & Validation (30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-CXifb6OTM_"
      },
      "source": [
        "X = df.iloc[:,:-1].copy()\n",
        "y = df.iloc[:,-1].copy()\n",
        "xtest = t_df.iloc[:,:-1].copy()\n",
        "ytest = t_df.iloc[:,-1].copy() \n",
        "\n",
        "xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, test_size=0.3, random_state=77, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05pT_ozRBiO4"
      },
      "source": [
        "## XGBOOST\n",
        "Please note this is not the Scikit-learn API but the python API: https://xgboost.readthedocs.io/en/latest/python/python_intro.html which provides better support for GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajZy3Fpw58mx"
      },
      "source": [
        "# instantiate params\n",
        "params = {}\n",
        "\n",
        "# general params\n",
        "general_params = {'silent': 1,\n",
        "                  'lambda': 0.02,\n",
        "                  'learning_rate': 0.07,\n",
        "                  'max_depth': 16}\n",
        "params.update(general_params)\n",
        "\n",
        "# booster params\n",
        "n_gpus = 1  # change this to -1 to use all GPUs available or 0 to use the CPU\n",
        "booster_params = {}\n",
        "\n",
        "if n_gpus != 0:\n",
        "    booster_params['tree_method'] = 'gpu_hist'\n",
        "    booster_params['n_gpus'] = n_gpus   \n",
        "params.update(booster_params)\n",
        "\n",
        "# learning task params\n",
        "learning_task_params = {}\n",
        "learning_task_params['eval_metric'] = ['logloss']\n",
        "learning_task_params['objective'] = 'reg:logistic'\n",
        "\n",
        "params.update(learning_task_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn66QJG0Fdv2"
      },
      "source": [
        "xgboost_model = XGBClassifier(**params, n_estimators=1000, early_stopping_rounds=10, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc8lKhroU0Ed"
      },
      "source": [
        "print(\"Train...\")\n",
        "%time xgboost_model.fit(xtrain, ytrain)\n",
        "\n",
        "print(\"\\nPredict (Validation)...\")\n",
        "%time y_pred = xgboost_model.predict(xvalid)\n",
        "predictions=[round(value) for value in y_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lym7UBXmglKU"
      },
      "source": [
        "### Prediction on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv76HTFqgr3C"
      },
      "source": [
        "# This is how many records we have in the validation set\n",
        "pd.Series(yvalid).value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_PwBuiWU3B_"
      },
      "source": [
        "accuracy = accuracy_score(yvalid, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(yvalid, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct90B0kRgYnX"
      },
      "source": [
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(yvalid, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\nConfusion Matrix on VALIDATION Set\", fontsize=27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_F4hpuYid4j"
      },
      "source": [
        "print(classification_report(yvalid,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abxtqK5a3Z_d"
      },
      "source": [
        "Not so good performance on class +50K (because our data is skewed. As stated in the medatada: picking someone at random will give us 93% chance of selecting someone on the -50K group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfehc4MvetkV"
      },
      "source": [
        "###  XGBoost with balanced and normalised data \n",
        "\n",
        "Let's try to normalise and upscale our '50K+' class. \n",
        "\n",
        "Ask me why I am not a big fan of upscaling...the explanation deserves a whole \"Colab Notebook\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyf9xiBptre_"
      },
      "source": [
        "X = df.iloc[:,:-1].copy()\n",
        "y = df.iloc[:,-1].copy()\n",
        "\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "X = pd.DataFrame(X, columns=df.iloc[:,:-1].columns)\n",
        "y = pd.Series(y); \n",
        "\n",
        "xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, test_size=0.3, random_state=77, shuffle=True)\n",
        "scaler = Normalizer().fit(xtrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y60lqhDYe2XR"
      },
      "source": [
        "xg_boost_model_norm = XGBClassifier(**params, n_estimators=1000, early_stopping_rounds=10, verbose=2)\n",
        "\n",
        "print(\"Train...\")\n",
        "%time xg_boost_model_norm.fit(xtrain, ytrain)\n",
        "\n",
        "print(\"\\nPredict (Validation)...\")\n",
        "%time y_pred = xg_boost_model_norm.predict(xvalid)\n",
        "predictions=[round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(yvalid, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(yvalid, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(yvalid, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\nConfusion Matrix on VALIDATION Set\", fontsize=27)\n",
        "\n",
        "print(div)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4hkMKX9hppa"
      },
      "source": [
        "print(classification_report(yvalid,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg3UG3dqARQ_"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Since this seems like a linear model, an alternative method to explore would be SVM. However, SVMs depend on \"support vectors\" and their large margins. It is very sensitive to unbalanced datasets e the data must be scaled (some people use PCA).\n",
        "\n",
        "SVM is robust, but it is time consuming with complecity that can reach $O(N^2*K)$. It is prohibitive unless we  use ensemble methods. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFXYeMJQN9Td"
      },
      "source": [
        "## Gaussian Mixture Model - GMM\n",
        "\n",
        "In many times I prefer using GMM over KNNs because it gives us the probabilisitic treshold (soft classification). Which we can use for stacking. In this example, I will a simple model for the sake of comparisons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcAfHUSYc7tX"
      },
      "source": [
        "gmm = GaussianMixture(n_components=2, \n",
        "                      tol=1e-4, \n",
        "                      max_iter=10000, \n",
        "                      init_params='kmeans', \n",
        "                      random_state=77,\n",
        "                      verbose_interval=100,\n",
        "                      verbose=1)\n",
        "\n",
        "%time gmm.fit(xtrain)\n",
        "predictions = gmm.predict(xvalid) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wZxkTJc7d_"
      },
      "source": [
        "accuracy = accuracy_score(yvalid, predictions)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(yvalid, predictions))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(yvalid, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\n GMM:: Confusion Matrix on VALIDATION Set\", fontsize=27)\n",
        "\n",
        "print(classification_report(yvalid,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxp2Put4VyYA"
      },
      "source": [
        "**How very terrible!** \n",
        "\n",
        "This is a fast but poorly performing model due to the data's nature. Although we have two classes, they don't resemble \"a mixture\" model: in higher dimensions we will have overlaps in the feature space which the GMM can't handle easily unless we do massive data munging or perform further tests **(a chi-square test would give us a good indication wether GMM is a good model, but I wanted to show a model with poor performance!)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLtiuLhPswa6"
      },
      "source": [
        "## Deep Learning\n",
        "I don't see why using deep learning in this scenario. But let's do it just for the sake of comparison (and out of curiosity)\n",
        "\n",
        "This type of classification problem seems ideal for tree-based and ensemble methods that combine weak-learners. DNN sound very _sexy_ (and hyped) but in fact that can be overkill in many linear problems (DNN are great for Computer Vision, Speech Recognition...). Especially in our case, our dataset $N$ - number of training examples - and $K$ - number of features - is not super large so there's little benefit a more complex model can bring. Besides, a vanilla-DNN (multilayer perceptron) may be just as good as logistic regression model, which is less complex than XGBoost.\n",
        "\n",
        "> 🤕 **Pain Point** \"coding\" Deep Learning is a repetitive task. @Dataiku makes it so much easier to run DL models...fine tune hyperparameters...\n",
        "\n",
        "I will not spend too much time on Hyperparameter tuning. \n",
        "\n",
        "Since this is a fairly \"light\" dataset, I'll leave it run for 50K epochs without patience or early stopping (I'd never do these arbitrary choices in real life!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ9uLUZs4rRf"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPejtjkc4rtf"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\") # We have a GPU!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8uBlOtD7qgG"
      },
      "source": [
        "nnx_train = torch.tensor(np.array(xtrain).astype(np.float32), device=device)\n",
        "nny_train = torch.tensor(np.array(ytrain).astype(np.float32), device=device)\n",
        "nnx_valid = torch.tensor(np.array(xvalid).astype(np.float32), device=device)\n",
        "nny_valid = torch.tensor(np.array(yvalid).astype(np.float32), device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBju08Bv945C"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self, n_features):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(n_features, 18)\n",
        "    self.fc2 = nn.Linear(18, 11)\n",
        "    self.fc3 = nn.Linear(11, 5)\n",
        "    self.fc4 = nn.Linear(5, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "deep_net = Net(nnx_train.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_ViJxNw4rL7"
      },
      "source": [
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "learning_rate=1e-5\n",
        "optimizer = torch.optim.Adam(deep_net.parameters(), lr=learning_rate, \n",
        "                             weight_decay=0.01) #Adam is a pretty common one\n",
        "\n",
        "tloss = []\n",
        "vloss = []\n",
        "tacc = []\n",
        "vacc = [] \n",
        "\n",
        "deep_net = deep_net.to(device)\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "  predicted = y_pred.ge(.5).view(-1) # if below 0.5, then -50K\n",
        "  return (y_true == predicted).sum().float() / len(y_true)\n",
        "\n",
        "epochs = 50000\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  y_pred = deep_net(nnx_train.float())\n",
        "  y_pred = torch.squeeze(y_pred.float())\n",
        "  tloss.append(loss_fn(y_pred, nny_train).item())\n",
        "  tacc.append(acc(nny_train, y_pred).cpu().detach().numpy().item())\n",
        "\n",
        "  yvalid_pred = deep_net(nnx_valid)\n",
        "  yvalid_pred = torch.squeeze(yvalid_pred) \n",
        "  vloss.append(loss_fn(yvalid_pred, nny_valid.float()).item())\n",
        "  vacc.append(acc(nny_valid, yvalid_pred).cpu().detach().numpy().item())\n",
        "\n",
        "  if epoch % 500 == 0:\n",
        "    print(f'''epoch {epoch} \n",
        "    TRAIN ---> loss: {round(tloss[-1],2)} \\t accuracy: {100*tacc[-1]}\n",
        "    VALID ---> loss: {round(vloss[-1],2)} \\t accuracy: {100*vacc[-1]}\n",
        "    ''')\n",
        "    print(div)\n",
        "\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss_fn(y_pred, nny_train).backward()\n",
        "  optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXsIc1ts4rAO"
      },
      "source": [
        "data = {'train_loss'  : tloss,\n",
        "        'train_acc'   : tacc,\n",
        "        'valid_loss'  : vloss,\n",
        "        'valid_acc'   : vacc}\n",
        "results = pd.DataFrame.from_dict(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIY9TFUVTciF"
      },
      "source": [
        "f, axs = plt.subplots(1,2, figsize=(17,8))\n",
        "\n",
        "axs[0].plot(results.train_acc)\n",
        "axs[0].plot(results.valid_acc)\n",
        "\n",
        "axs[1].plot(results.train_loss)\n",
        "axs[1].plot(results.valid_loss)\n",
        "\n",
        "axs[0].set_ylim(ymin=0.4, ymax=1)\n",
        "axs[1].set_ylim(ymin=0.0, ymax=max(np.max(vloss), np.max(tloss)))\n",
        "\n",
        "axs[0].set_xlim(xmin=0.0, xmax=epochs)\n",
        "axs[1].set_xlim(xmin=0.0, xmax=epochs)\n",
        "\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[1].set_ylabel('Loss')\n",
        "\n",
        "\n",
        "axs[0].set_title('Accuracy')\n",
        "axs[1].set_title('Loss')\n",
        "\n",
        "\n",
        "classes = ['-50K', '+50K']\n",
        "\n",
        "predictions = deep_net(nnx_valid)\n",
        "predictions = predictions.ge(.5).view(-1).cpu()\n",
        "y_test = yvalid\n",
        "\n",
        "print(classification_report(yvalid,predictions, target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAf3W7u3aYBR"
      },
      "source": [
        "This is far too easy dataset for Deep Learning. Loss decreases very quickly, but accuracy is not yet pair with XGBoost. We would require lots of fine-tuning to get it to 98% accuracy. For this particular case, as mentioned, tree-based methods seem to be the best choice.\n",
        "\n",
        "**Good outcomes:** a ~85% accuracy on a \"toy\" example doesn't sound *too bad*... Besides, it performed worse than XGBoost on classifying both \"-50K\" and \"-50K\" with the oversampled and normalised data. The architecture I have used is rather simple and accounts for non-linearity, so perhaps adding more features, in this case, could help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbUNXCVCOA7n"
      },
      "source": [
        "# Evaluations on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgsCSCXYOzth"
      },
      "source": [
        "## XGBoost (Standard) on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpBWKrFOmKp"
      },
      "source": [
        "# This is how many values we have in the Test Set\n",
        "ytest.value_counts()\n",
        "\n",
        "print(\"\\nPredict (Test)...\")\n",
        "y_pred=xgboost_model.predict(xtest[df.iloc[:,:-1].columns])\n",
        "predictions=[round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(ytest, predictions)\n",
        "print(\"Accuracy: %.3f%%\" % (accuracy * 100.0))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(ytest, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(ytest, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\nXGBoost:: Confusion Matrix on Test Set\", fontsize=27)\n",
        "print(classification_report(ytest,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CShhrJLaO9NJ"
      },
      "source": [
        "## XGBoost (Normalised, Oversampled) on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n1dUz5APCdX"
      },
      "source": [
        "print(\"\\nPredict (Test)...\")\n",
        "y_pred = xg_boost_model_norm.predict(xtest[df.iloc[:,:-1].columns])\n",
        "predictions=[round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(ytest, predictions)\n",
        "print(\"Accuracy: %.3f%%\" % (accuracy * 100.0))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(ytest, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(ytest, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\n XGBoost (Norm, Upscaled):: Confusion Matrix on Test Set\", fontsize=27)\n",
        "\n",
        "print(classification_report(ytest,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTn71N1cPYVx"
      },
      "source": [
        "> **Oh no! It seems like that the SMOTE method makes us overfit in the validation set.** I still prefer the non-scaled method as it helps us generalise better onto unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs9RdCqje1Df"
      },
      "source": [
        "## GMM on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "346S5yAlYo5p"
      },
      "source": [
        "print(\"\\nPredict (Test)...\")\n",
        "y_pred = gmm.predict(xtest[df.iloc[:,:-1].columns])\n",
        "predictions=[round(value) for value in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(ytest, predictions)\n",
        "print(\"Accuracy: %.3f%%\" % (accuracy * 100.0))\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(ytest, y_pred))\n",
        "print(\"RMSE: %f\" % (rmse))\n",
        "\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(ytest, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\nGMM : Confusion Matrix on Test Set\", fontsize=27)\n",
        "\n",
        "print(classification_report(ytest,predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVhbdrM8lHJU"
      },
      "source": [
        "**Interesting** overall performance on the test set was much better than in the validation set (relative only to the GMM model). This is a clear example of high bias in the training vs validation set. Yet, it seriously fails on class 1 (50K+) due to the limited data in the test set (we don't upscale the test set!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnqHMDcrfMyf"
      },
      "source": [
        "## Deep Learning on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hLxfXv9b5Zb"
      },
      "source": [
        "nnx_test = torch.tensor(np.array(xtest[df.iloc[:,:-1].columns]).astype(np.float32), device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kacll-HfaSAI"
      },
      "source": [
        "classes = ['-50K', '+50K']\n",
        "\n",
        "predictions = deep_net(nnx_test)\n",
        "predictions = predictions.ge(.5).view(-1).cpu()\n",
        "y_test = ytest\n",
        "\n",
        "with sns.axes_style(\"white\"):\n",
        "  f, ax = plt.subplots(figsize=(13,13))\n",
        "  ax = sns.heatmap(confusion_matrix(ytest, predictions),\n",
        "              square=True,\n",
        "              center=0.0,\n",
        "              cmap=\"coolwarm\",\n",
        "              linecolor='white',\n",
        "              linestyle = '--',\n",
        "              rasterized=False,\n",
        "              edgecolor='white',\n",
        "              capstyle='projecting',\n",
        "              linewidth=2,\n",
        "              annot=True, \n",
        "              fmt=\"d\",\n",
        "              robust=True,\n",
        "              cbar=False,\n",
        "              yticklabels=[\"-50K\", \"50K+\"],\n",
        "              xticklabels=[\"-50K\", \"50K+\"],\n",
        "              annot_kws={'fontsize': 17},\n",
        "              cbar_kws={\"location\": \"top\",\n",
        "                        'use_gridspec': False,\n",
        "                        \"label\": \"Correlation Coefficient\",\n",
        "                        'shrink': 0.8})\n",
        "\n",
        "plt.suptitle(\"\\n Deep Learning:: Confusion Matrix on Test Set\", fontsize=27)\n",
        "\n",
        "print(classification_report(ytest,predictions, target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuCP25hufYS5"
      },
      "source": [
        "## Conclusion / Model Selection\n",
        "\n",
        "Choosing which model to go head depends on the objective and the metric. But we can say that, in this particular case, without much tuning, XGBoost in its standard version is a sufficiently good model (in comparison to others)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWj-lhIypWFq"
      },
      "source": [
        "end_time = time.time()\n",
        "elapsed = end_time - start_time\n",
        "print(div)\n",
        "print(\"Elapsed Time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed)))\n",
        "print(div)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT3-GY_SYwMi"
      },
      "source": [
        "#THE END ✌\n",
        "\n",
        "\n",
        "**Some questions to reflect upon:**\n",
        "\n",
        "1. **Normalise / scale the data?**\n",
        "SVM exploits distances and similarities from large margins so it needs some sort of scaling to avoid creating support vectors that are wrongfully importance. I chose Normalisation because it uses 'l2' norm and makes the data resemble a gaussian distribution which is almost always convenient for probabilistic models. This form of scaling is good for the linear kernel on SVMs, but XGBoost is a tree based ensemble, which is scale invariant, so it doesn't require scaling. This is evidenced by the fact that XGBoost scaled and normalised performed well on validation set, but faily simililarly on Test Set\n",
        "\n",
        "2. **Caveats with oversample / downsample?**\n",
        "I prefer modelling upon the true nature of the data, choosing models that are less sensitive to scale imbalance or that accounts for it in a proper way. There are several other techniques to deal with this issue such as downsampling, stratified oversampling, etc... \n",
        "\n",
        "3. **No feature creation?**\n",
        "We have a dataset that is not very large and that is not showing signs severe overfitting given the results in the validation and test sets on Standard XGBoost. So the trade-off bias / variance shouldn't be a great issue for this particular model. With 41 features and less than 200K training examples, feature engineering might be overkill and lead to overfitting. It's better to first come up with a good model. *The metadata* states: *Probability for the label '- 50000' : 93.80% *and *Probability for the label '50000+' : 6.20%*, so in this dataset it is not so straight-forward to shoot new features into the model. As for the other models, we have oversampled the data, so, as expected, with exception of GMM, they perform well on validation set and worse on test set. These are signs of overfitting and in this case feature engineering (for example, creating polynomial features) could help, especially in the Deep Learning model which handles well non-linearity.\n",
        "\n",
        "5. **More EDA?**\n",
        "Since I knew the objective was classification over a linearly-separable setting, I focused on EDA for model preparation understanding rather than trying to understand US' macroeconomy. There are several questions to ask (more hypothesis) such as the relationship between race, sex and wage. Wether citizenship is related to industry, etc.... it depends on the objetive of the analysis. \n",
        "\n",
        "6. **Deep Learning?**\n",
        "Overkill for a (relatively) small mostly-linearly-separable training set. As we can see, decent performance (how much is good enough?) is obtained with XGBoost straightaway \n",
        "\n",
        "7. **Future work?** Defintely. There are so many ways to improve this notebook. More experiments, more models, more EDAs, use of external data, change the target variable. We could try model ensembles, stacking, etc.... In short, there are many possibilities to explore and this can be an (theoretically) endless notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07gAtt54feTd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}